#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\renewcommand{\listtablename}{Indice de tablas}
\renewcommand{\tablename}{Tabla} 
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language spanish
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize 12
\spacing double
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 1.5cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Machine Learning
\end_layout

\begin_layout Standard
En esta sección se realiza un breve repaso sobre conceptos básicos que envuelven
 a Machine Learning.
 El objetivo es visualizar qué aspectos de Machine Learning fueron tomados
 como componentes de solución al problema de estudio.
\end_layout

\begin_layout Section
Definición
\end_layout

\begin_layout Standard
En 1959 Arthur Samuel en una publicación escribió: 
\shape italic

\begin_inset Quotes eld
\end_inset

Programming computers to learn from experience should eventually eliminate
 the need for much of this detailed programming effort
\begin_inset Quotes erd
\end_inset


\shape default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Arthur1959"

\end_inset

.
 Este pionero de machine learning ya presagiaba que los programas, a partir
 del aprendizaje sobre datos históricos (la experiencia), podrían efectuar
 tareas de toma de decisiones sin ser programadas explícitamente dichas
 decisiones.
\end_layout

\begin_layout Standard
Samuel define machine learning como sigue: 
\shape italic

\begin_inset Quotes eld
\end_inset

Machine Learning es un campo de estudio que da a las computadoras la capacidad
 de aprender sin ser explícitamente programadas
\begin_inset Quotes erd
\end_inset


\shape default
.
 Otro investigador de machine learning Tom Mitchell propuso en 1998 la siguiente
 definición: 
\shape italic

\begin_inset Quotes eld
\end_inset

Well posed Learning Problem: A computer program is said to learn from experience
 E with respect to some task T and some performance measure P, if its performanc
e on T, as measured by P, improves with experience E
\begin_inset Quotes erd
\end_inset


\shape default
.
 Donde se nos indica que el aprendizaje en las máquinas deberá ser parecido
 al aprendizaje en los humanos, por ejemplo cuando una criatura comienza
 a hablar a través de la experiencia de pronunciar las palabras y de su
 interacción con otras personas, entonces sucede que su capacidad de hablar
 se va perfeccionando o mejorando.
\end_layout

\begin_layout Standard

\shape italic
\begin_inset Quotes eld
\end_inset

The purpose of machine learning is to learn from training data in order
 to make as good as possible predictions on new, unseen, data
\begin_inset Quotes erd
\end_inset


\shape default

\begin_inset CommandInset citation
LatexCommand cite
key "Jean2016"

\end_inset

.
 La dificultad radica en que debemos construir modelos que nos acerquen
 a una buena predicción sobre datos aún no conocidos o imprevistos.
 Peter Prettenhofer y Gille Louppe presentan la siguiente definición:
\end_layout

\begin_layout Standard
Data comes as...
\end_layout

\begin_layout Itemize
A set of examples 
\begin_inset Formula $\left\{ \left(x_{i},y_{i}\right)\mid0\leq i<n\;samples\right\} $
\end_inset

, with
\end_layout

\begin_deeper
\begin_layout Itemize
Feature vector 
\begin_inset Formula $x\in\mathbb{R}^{n\;features}$
\end_inset

, and
\end_layout

\begin_layout Itemize
Response 
\begin_inset Formula $y\in\mathbb{R}$
\end_inset

(regression) or 
\begin_inset Formula $y\in\left\{ -1,1\right\} $
\end_inset

 (classification)
\end_layout

\end_deeper
\begin_layout Itemize
Goal is to...
\end_layout

\begin_deeper
\begin_layout Itemize
Find a function 
\begin_inset Formula $ŷ=f\left(x\right)$
\end_inset


\end_layout

\begin_layout Itemize
Such that error 
\begin_inset Formula $L\left(y,ŷ\right)$
\end_inset

on new (unseen) 
\begin_inset Formula $x$
\end_inset

 is minimal
\end_layout

\end_deeper
\begin_layout Section
Categorías de los algoritmos
\end_layout

\begin_layout Standard
Los algoritmos de aprendizaje automático se pueden categorizar según la
 forma en que se realiza el aprendizaje, pero teniendo en cuenta que todos
 reciben un conjunto de ejemplos del que aprender.
\end_layout

\begin_layout Subsection
Aprendizaje supervisado
\end_layout

\begin_layout Standard
El algoritmo recibe datos de entrenamiento que contienen la respuesta correcta
 para cada ejemplo.
 El problema de estudio utiliza algoritmos de aprendizaje supervisado, donde
 el experto en compras da la respuesta correcta a cada ejemplo.
\end_layout

\begin_layout Subsection
Aprendizaje no supervisado
\end_layout

\begin_layout Standard
El algoritmo busca estructuras en los datos de entrenamiento, como encontrar
 qué ejemplos son similares entre sí, y agruparlos en clusters.
\end_layout

\begin_layout Section
Tipos de problemas
\end_layout

\begin_layout Standard
Teniendo en cuenta las clases de problemas que los algoritmos de aprendizaje
 pueden resolver, los tipos de problemas se pueden agrupar como sigue.
\end_layout

\begin_layout Subsection
Regresión
\end_layout

\begin_layout Standard
Un problema de aprendizaje supervisado donde la respuesta a aprender es
 un valor continuo.
\end_layout

\begin_layout Subsection
Clasificación
\end_layout

\begin_layout Standard
Un problema de aprendizaje supervisado donde la respuesta a aprender es
 un valor de un conjunto finito de posibles valores discretos.
 El problema de estudio se encara como un problema de clasificación, donde
 hay cuatro posibles valores discretos.
\end_layout

\begin_layout Subsection
Segmentación
\end_layout

\begin_layout Standard
Un problema de aprendizaje no supervisado donde la estructura a aprender
 es un conjunto de clusters donde cada cluster tiene similares ejemplos.
\end_layout

\begin_layout Subsection
Análisis de red
\end_layout

\begin_layout Standard
Un problema de aprendizaje no supervisado donde la estructura a aprender
 es información acerca de la importancia y el rol de los nodos en una red.
\end_layout

\begin_layout Section
Problemas de clasificación
\end_layout

\begin_layout Standard
En los problemas de clasificación el modelo creado debe predecir la clase,
 tipo o categoría de la salida.
\end_layout

\begin_layout Subsection
Clasificación binaria
\end_layout

\begin_layout Standard
En su forma más simple se reduce a la siguiente cuestión: dado un patrón
 
\begin_inset Formula $x$
\end_inset

 extraído de un dominio 
\begin_inset Formula $X$
\end_inset

, estimar qué valor asumirá una variable aleatoria binaria asociada 
\begin_inset Formula $y\in\left\{ \pm1\right\} $
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
\end_layout

\begin_layout Subsection
Clasificación multiclase
\end_layout

\begin_layout Standard
Es la extensión lógica de la clasificación binaria.
 La principal diferencia es que ahora 
\begin_inset Formula $y\in\left\{ 1,2,3..,N\right\} $
\end_inset

 puede asumir un rango de valores diferentes 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
 El problema de estudio utiliza clasificación multiclase, donde 
\begin_inset Formula $y\in\left\{ Nada,Poco,Medio,Mucho\right\} $
\end_inset


\end_layout

\begin_layout Section
Esquema de machine learning 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset


\end_layout

\begin_layout Standard
Para desarrollar un modelo o esquema de machine learning es necesario conocer
 los componentes esenciales que la forman.
\end_layout

\begin_layout Subsection
Ejemplos o instancias
\end_layout

\begin_layout Standard
La entrada de un esquema de aprendizaje automático es un conjunto de instancias.
 Estas instancias son las cosas que deben ser clasificadas, asociadas o
 agrupadas.
 En el escenario estándar, cada instancia es un ejemplo individual e independien
te del concepto que se debe aprender.
 Para el problema de estudio el proceso de Business Intelligence es quien
 provee las instancias.
\end_layout

\begin_layout Subsection
Características o atributos
\end_layout

\begin_layout Standard
Las instancias son caracterizadas mediante los valores de un conjunto predetermi
nado de atributos.
 Cada instancia proporciona una entrada al aprendizaje automático y es caracteri
zado por los valores de un conjunto fijo y predefinido de características
 o atributos.
\end_layout

\begin_layout Subsection
Etiquetas
\end_layout

\begin_layout Standard
Las cantidades nominales tienen valores que son símbolos distintos.
 Los valores mismos sirven como etiquetas o nombres, de ahí el término nominal,
 que viene de la palabra latina para nombre.
 Los atributos nominales a veces se llaman categorizados, enumerados o discretos.
\end_layout

\begin_layout Subsection
Conjunto de entrenamiento
\end_layout

\begin_layout Standard
El grupo de ejemplos utilizados en el proceso de entrenamiento de los algoritmos
 de aprendizaje automático constituyen el conjunto de entrenamiento.
\end_layout

\begin_layout Subsection
Algoritmos de aprendizaje
\end_layout

\begin_layout Standard
Hipótesis, Parámetros, Función de costo, Objetivo.
\end_layout

\begin_layout Subsection
Conjunto de prueba
\end_layout

\begin_layout Standard
Para predecir el rendimiento de un clasificador sobre nuevos datos, necesitamos
 evaluar su tasa de error en un conjunto de datos que no desempeñó ningún
 papel en la formación del clasificador.
 Este conjunto de datos independiente se denomina conjunto de prueba.
\end_layout

\begin_layout Section
Algoritmos de clasificación en WEKA
\end_layout

\begin_layout Standard
Weka es una colección de algoritmos de aprendizaje automático para tareas
 de minería de datos.
 Los algoritmos pueden ser aplicados directamente a un conjunto de datos
 o llamados desde código Java.
 Weka contiene herramientas para pre-procesamiento de datos, clasificación,
 regresión, clustering, reglas de asociación y visualización.
 También es adecuado para desarrollar nuevos esquemas de aprendizaje automático
 
\begin_inset CommandInset citation
LatexCommand citet
key "Weka3"

\end_inset

.
 En el problema de estudio se utiliza el conjunto de algoritmos de clasificación
 de Weka 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2016"

\end_inset

.
 En la tabla 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:algoritmosWekaVsReales"

\end_inset

 se listan los algoritmos de clasificación en Weka asociados a los nombres
 de algoritmos o estrategias que implementan.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align left
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:algoritmosWekaVsReales"

\end_inset

Clasificadores Weka 
\begin_inset CommandInset citation
LatexCommand cite
key "WekaCla"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\size small
\begin_inset Tabular
<lyxtabular version="3" rows="18" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="left" valignment="top" width="4cm">
<column alignment="left" valignment="top" width="10cm">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores Weka
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Algoritmo que implementa
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
BayesNet
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Bayes Network learning algorithms.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
NaiveBayes
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Naive Bayes classifier.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
NaiveBayesUpdateable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Updateable version of NaiveBayes.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Logistic
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Using multinomial logistic regression model.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
MultilayerPerceptron
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Uses backpropagation to classify instances.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
SimpleLogistic
\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
LogitBoost with simple regression.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
SMO
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sequential Minimal Optimization algorithm for training a support vector
 classifier.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
OneR
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Using a 1R classifier.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
DecisionTable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Using a simple decision table majority classifier.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
JRip
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Implements a propositional rule learner, Repeated Incremental Pruning to
 Produce Error Reduction (RIPPER).
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
PART
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
PART decision list.
 Uses separate-and-conquer.
 Builds a partial C4.5 decision tree.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
ZeroR
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Using a 0-R classifier.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
DecisionStump
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Using a decision stump.
 Usually used in conjunction with a boosting algorithm.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
J48
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Pruned or unpruned C4.5 decision tree.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
LMT
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Logistic model trees.
 Classification trees with logistic regression.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
RandomForest
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Forest of random trees.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
REPTree
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Fast decision tree learner.
 Builds a decision/regression tree.
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Los algoritmos de clasificación de Weka que se utilizarán es el siguiente
 
\begin_inset CommandInset citation
LatexCommand cite
key "WekaCla"

\end_inset

:
\end_layout

\begin_layout Subsection
BayesNet
\end_layout

\begin_layout Standard
Bayes Network learning using various search algorithms and quality measures.
 Base class for a Bayes Network classifier.
 Provides datastructures (network structure, conditional probability distributio
ns, etc.) and facilities common to Bayes Network learning algorithms like
 K2 and B.
\end_layout

\begin_layout Subsection
NaiveBayes
\end_layout

\begin_layout Standard
Class for a Naive Bayes classifier using estimator classes.
 Numeric estimator precision values are chosen based on analysis of the
 training data.
 For this reason, the classifier is not an UpdateableClassifier (which in
 typical usage are initialized with zero training instances).
\end_layout

\begin_layout Subsection
NaiveBayesUpdateable
\end_layout

\begin_layout Standard
Class for a Naive Bayes classifier using estimator classes.
 This is the updateable version of NaiveBayes.
 This classifier will use a default precision of 0.1 for numeric attributes
 when buildClassifier is called with zero training instances.
\end_layout

\begin_layout Subsection
Logistic
\end_layout

\begin_layout Standard
Class for building and using a multinomial logistic regression model with
 a ridge estimator.
 If there are k classes for n instances with m attributes, the parameter
 matrix B to be calculated will be an m*(k-1) matrix.
\end_layout

\begin_layout Subsection
MultilayerPerceptron
\end_layout

\begin_layout Standard
A Classifier that uses backpropagation to classify instances.
 This network can be built by hand, created by an algorithm or both.
 The network can also be monitored and modified during training time.
 The nodes in this network are all sigmoid (except for when the class is
 numeric in which case the the output nodes become unthresholded linear
 units).
\end_layout

\begin_layout Subsection
SimpleLogistic
\end_layout

\begin_layout Standard
Classifier for building linear logistic regression models.
 LogitBoost with simple regression functions as base learners is used for
 fitting the logistic models.
 The optimal number of LogitBoost iterations to perform is cross-validated,
 which leads to automatic attribute selection.
\end_layout

\begin_layout Subsection
SMO
\end_layout

\begin_layout Standard
Implements John Platt's sequential minimal optimization algorithm for training
 a support vector classifier.
 This implementation globally replaces all missing values and transforms
 nominal attributes into binary ones.
 It also normalizes all attributes by default.
 (In that case the coefficients in the output are based on the normalized
 data, not the original data --- this is important for interpreting the
 classifier).
 Multi-class problems are solved using pairwise classification (aka 1-vs-1).
 To obtain proper probability estimates, use the option that fits calibration
 models to the outputs of the support vector machine.
 In the multi-class case, the predicted probabilities are coupled using
 Hastie and Tibshirani's pairwise coupling method.
 
\end_layout

\begin_layout Subsection
OneR
\end_layout

\begin_layout Standard
Class for building and using a 1R classifier; in other words, uses the minimum-e
rror attribute for prediction, discretizing numeric attributes.
\end_layout

\begin_layout Subsection
DecisionTable
\end_layout

\begin_layout Standard
Class for building and using a simple decision table majority classifier.
\end_layout

\begin_layout Subsubsection
JRip
\end_layout

\begin_layout Standard
This class implements a propositional rule learner, Repeated Incremental
 Pruning to Produce Error Reduction (RIPPER), which was proposed by William
 W.
 Cohen as an optimized version of IREP.
 
\end_layout

\begin_layout Subsubsection
PART
\end_layout

\begin_layout Standard
Class for generating a PART decision list.
 Uses separate-and-conquer.
 Builds a partial C4.5 decision tree in each iteration and makes the "best"
 leaf into a rule.
\end_layout

\begin_layout Subsubsection
ZeroR
\end_layout

\begin_layout Standard
Class for building and using a 0-R classifier.
 Predicts the mean (for a numeric class) or the mode (for a nominal class).
\end_layout

\begin_layout Subsubsection
DecisionStump
\end_layout

\begin_layout Standard
Class for building and using a decision stump.
 Usually used in conjunction with a boosting algorithm.
 Does regression (based on mean-squared error) or classification (based
 on entropy).
 Missing is treated as a separate value.
\end_layout

\begin_layout Subsubsection
J48
\end_layout

\begin_layout Standard
Class for generating a pruned or unpruned C4.5 decision tree.
\end_layout

\begin_layout Subsubsection
LMT
\end_layout

\begin_layout Standard
Classifier for building 'logistic model trees', which are classification
 trees with logistic regression functions at the leaves.
 The algorithm can deal with binary and multi-class target variables, numeric
 and nominal attributes and missing values.
\end_layout

\begin_layout Subsubsection
RandomForest: Class for constructing a forest of random trees.
\end_layout

\begin_layout Subsubsection
RandomTree: Class for constructing a tree that considers K randomly chosen
 attributes at each node.
 Performs no pruning.
 Also has an option to allow estimation of class probabilities (or target
 mean in the regression case) based on a hold-out set (backfitting).
 
\end_layout

\begin_layout Subsubsection
REPTree: Fast decision tree learner.
 Builds a decision/regression tree using information gain/variance and prunes
 it using reduced-error pruning (with backfitting).
 Only sorts values for numeric attributes once.
 Missing values are dealt with by splitting the corresponding instances
 into pieces (i.e.
 as in C4.5).
\end_layout

\begin_layout Section
Evaluación del aprendizaje
\end_layout

\begin_layout Standard
La evaluación es la clave para lograr avances reales en el aprendizaje automátic
o.
 Entre las técnicas de evaluación se destacan la Validación Cruzada (Cross-Valid
ation) y la Validación Cruzada k-pliegues Estratificado (Stratified k-fold
 Cross-Validation).
 
\end_layout

\begin_layout Standard
La técnica de Cross-Validation consiste en dividir los datos en un número
 de pliegues o particiones, si por ejemplo elegimos cuatro, entonces cada
 partición se utiliza para las pruebas y las demás para el entrenamiento,
 al repetir este proceso 4 veces se consigue que cada partición se haya
 utilizado una vez como conjunto de pruebas.
 
\end_layout

\begin_layout Standard
La técnica estándar para predecir la tasa de error es Stratified k-fold
 Cross-Validation, donde la estratificación se refiere al proceso de reorganizar
 los datos de tal manera a asegurar que cada pliegue sea una buena representació
n del conjunto.
 Comúnmente se acepta que 10 es el número de pliegues con el que se obtiene
 la mejor estimación de error, idea basada en diversas pruebas sobre conjuntos
 de datos diferentes y para distintas técnicas de aprendizaje 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
Otra técnica es el Porcentaje de División (Percentage Split) con el que
 puede retener para la prueba un determinado porcentaje de los datos.
 Es una alternativa utilizar un conjunto de pruebas separado o una división
 porcentual de los datos de entrenamiento.
 Si elegimos 60% como porcentaje de división, entonces el conjunto de prueba
 se constituirá con el 40% de las instancias y el conjunto de entrenamiento
 con el 60% de las instancias.
\end_layout

\begin_layout Section
Métricas de desempeño 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset


\end_layout

\begin_layout Standard
Para los problemas de clasificación, es natural medir el rendimiento de
 un clasificador en términos de la tasa de error (error rate).
 El clasificador predice la clase de cada instancia: si es correcta se cuenta
 como un éxito, sino se cuenta como un error.
 La tasa de error es sólo la proporción de errores cometidos sobre un conjunto
 de instancias, y mide el rendimiento general del clasificador.
 Por supuesto, lo que nos interesa es el probable desempeño futuro en nuevos
 datos, no el rendimiento pasado en datos antiguos.
\end_layout

\begin_layout Standard
Para predecir el rendimiento de un clasificador en nuevos datos, necesitamos
 evaluar su tasa de error en un conjunto de datos que no desempeñó ningún
 papel en la formación del clasificador.
 Este conjunto de datos independiente se denomina conjunto de prueba.
 En tales situaciones se suele hablar de tres conjuntos de datos: los datos
 de entrenamiento, los datos de validación y los datos de prueba.
 
\end_layout

\begin_layout Standard
Los datos de entrenamiento son utilizados por uno o más esquemas de aprendizaje
 para conocer clasificadores.
 Los datos de validación se utilizan para optimizar los parámetros de los
 clasificadores, o para seleccionar uno determinado.
 A continuación, los datos de prueba se utilizan para calcular la tasa de
 error del método final optimizado.
 Cada uno de los tres conjuntos debe ser independiente: El conjunto de validació
n debe ser diferente del conjunto de entrenamiento para obtener un buen
 desempeño en la etapa de optimización o selección y el conjunto de pruebas
 debe ser diferente de ambos para obtener una estimación confiable de la
 tasa de error real.
\end_layout

\begin_layout Subsection
Aciertos
\end_layout

\begin_layout Standard
Número de instancias correctamente clasificadas.
\end_layout

\begin_layout Subsection
Porcentaje de Aciertos
\end_layout

\begin_layout Standard
Porcentaje de instancias correctamente clasificadas.
\end_layout

\begin_layout Subsection
Estadística Kappa (Kappa Statistic)
\end_layout

\begin_layout Standard
En problemas de clasificación para aplicaciones reales normalmente los errores
 cuestan diferentes cantidades.
 Por ejemplo en bancos y financieras el costo de prestar a una persona que
 no paga sus deudas es mayor que el costo de rechazar un préstamo a una
 persona que es pagadora.
 Los Verdaderos Positivos (True Positive - TP) y Verdaderos Negativos (True
 Negative - TN) son clasificaciones correctas.
 Un Falso Positivo (False Positive - FP) es cuando el resultado se predice
 incorrectamente como sí (o positivo) cuando es realmente no (o negativo).
 Un Falso Negativo (False Negative - FN) es cuando el resultado se predice
 incorrectamente como negativo cuando es realmente positivo.
 En la predicción multiclase, cada elemento de la matriz de confusión muestra
 el número de ejemplos de prueba para los que la clase real es la fila y
 la clase prevista es la columna.
 Son buenos resultados los grandes números en la diagonal principal e idealmente
 cero fuera de la diagonal principal.
 
\begin_inset Quotes eld
\end_inset

Kappa se utiliza para medir el acuerdo entre la predicción y la observación
 de las categorizaciones de un conjunto de datos, mientras que se corrige
 para un acuerdo que ocurre por casualidad
\begin_inset Quotes erd
\end_inset

.
 Si los evaluadores están totalmente de acuerdo Kappa alcanza un valor máximo
 igual a 1.
 Si no hay total acuerdo entre los evaluadores, entonces Kappa tiene un
 valor 
\begin_inset Formula $<1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\kappa=\frac{Pr\left(a\right)-Pr\left(e\right)}{1-Pr\left(e\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde: 
\begin_inset Formula $Pr\left(a\right)$
\end_inset

 es el acuerdo observado relativo entre los observadores y 
\begin_inset Formula $Pr\left(e\right)$
\end_inset

 es la probabilidad hipotética de acuerdo al azar utilizando los datos observado
s para calcular las probabilidades de que cada observador clasifique aleatoriame
nte cada categoría.
\end_layout

\begin_layout Subsection
Sensibilidad (Recall)
\end_layout

\begin_layout Standard
Calcula la sensibilidad con respecto a una clase en particular, esto se
 define como: positivos correctamente clasificados / positivos totales.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Recall=\frac{TP}{TP+FN}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Precisión (Precision)
\end_layout

\begin_layout Standard
Calcula la precisión con respecto a una clase en particular, esto se define
 como: positivos correctamente clasificados / total predicho como positivo.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Precision=\frac{TP}{TP+FP}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Puntuación-F (F-Measure)
\end_layout

\begin_layout Standard
La Puntuación-F es una medida de la exactitud de una prueba.
 La Puntuación-F puede interpretarse como un promedio ponderado de la precisión
 y sensibilidad, donde alcanza su mejor valor en 1 y el peor en 0.
 Se define como: 2 * Recall * Precision / (Recall + Precision).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
F-Measure=\frac{2*Recall*Precision}{\left(Recall+Precision\right)}
\end{equation}

\end_inset


\end_layout

\end_body
\end_document
