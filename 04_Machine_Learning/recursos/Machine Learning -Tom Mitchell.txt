
[MACHINE LEARNING BIAS, STATISTICAL BIAS, AND STATISTICAL VARIANCE OF DECISION TREE ALGORITHMS]

Several authors have pointed out that every inductive learning algorithm must adopt a bias in order to generalize beyond the training data

	Varios autores han señalado que cada algoritmo de aprendizaje inductivo debe adoptar un sesgo para generalizar más allá de los datos de entrenamiento

Without a bias, all possible functions must be entertained as hypotheses, and, taken together, these functions predict that all possible future outcomes are equally likely, so they cannot provide a basis for generalization or prediction. The bias of a learning algorithm|if it can be formulated explicitly | provides a specification for the desired behavior of the algorithm and clarifies the design and implementation of machine learning algorithms. In the remainder of this paper, we will call this kind of bias, the machine learning bias or ML bias

	Sin un sesgo, todas las funciones posibles deben ser entretenidas como hipótesis, y, en conjunto, estas funciones predicen que todos los posibles resultados futuros son igualmente probables, por lo que no pueden proporcionar una base para la generalización o la predicción. El sesgo de un algoritmo de aprendizaje | si puede formularse explícitamente | proporciona una especificación para el comportamiento deseado del algoritmo y aclara el diseño y la implementación de algoritmos de aprendizaje automático. En el resto de este documento, llamaremos a este tipo de sesgo, el sesgo de aprendizaje automático o el sesgo de ML

In statistics, the term "bias" is used in a more precise, but not entirely unrelated way. The bias of a learning algorithm (for a given learning problem and a fixed size m for training sets) is the persistent or systematic error that the learning algorithm is expected to make when trained on training sets of size m

	En las estadísticas, el término "sesgo" se usa de una manera más precisa, pero no del todo no relacionada. El sesgo de un algoritmo de aprendizaje (para un problema de aprendizaje dado y un tamaño fijo m para los conjuntos de entrenamiento) es el error persistente o sistemático que se espera que el algoritmo de aprendizaje cuando se entrena en el entrenamiento de conjuntos de tamaño m

[ELEMENST OF STATISTICAL LEARNING]

In machine learning, the term "bias" was introduced by Mitchell (1980) to mean "any basis for choosing one generalization [hypothesis] over another, other than strict consistency with the observed training instances." Examples of such biases include absolute biases and relative biases. An absolute bias is an assumption by the learning algorithm that the target function to be learned is definitely a member of some designated set of functions (such as the set of linear discriminate functions or the set of boolean conjunctions). A relative bias is an assumption that the function to learned is more likely to be from one set of functions than from another

	En el aprendizaje de máquina, el término "sesgo" fue introducido por Mitchell (1980) como "cualquier base para elegir una generalización [hipótesis] sobre otro, que no sea estricta coherencia con las instancias de formación observadas." Los ejemplos de tales sesgos incluyen sesgos absolutos y sesgos relativos. Un sesgo absoluto es una suposición por el algoritmo de aprendizaje que la función objetivo a ser aprendido es sin duda un miembro de un conjunto designado de funciones (tales como el conjunto de funciones discriminantes lineales o el conjunto de conjunciones booleanas). Un sesgo relativo es una suposición de que la función para aprender es más probable que sea de un conjunto de funciones que de otro


In statistics, the term "bias" is used in a more precise, but not entirely unrelated way. The bias of a learning algorithm (for a given learning problem and a fixed size m for training sets) is the persistent or systematic error that the learning algorithm is expected to make when trained on training sets of size m

	En las estadísticas, el término "sesgo" se usa de una manera más precisa, pero no del todo no relacionada. El sesgo de un algoritmo de aprendizaje (para un problema de aprendizaje dado y un tamaño fijo para m conjuntos de entrenamiento) es el error persistente o sistemático que se espera que el algoritmo de aprendizaje para que cuando entrenados en conjuntos de entrenamiento de tamaño m
	
The bias term is the squared difference between the true mean f(x0) and the expected value of the estimate — [ET (fˆk(x0)) − f(x0)]2—where the expectation averages the randomness in the training data. This term will most likely increase with k, if the true function is reasonably smooth

	El término de sesgo es la diferencia al cuadrado entre la verdadera media f (x0) y el valor esperado de la estimación - [ET (fk (x0)) - f (x0)] 2-donde la expectativa promedia la aleatoriedad en los datos de entrenamiento. Este término muy probablemente aumentará con k, si la función verdadera es razonablemente suave
	
The variance term is simply the variance of an average here, and decreases as the inverse of k. So as k varies, there is a bias–variance tradeoff. More generally, as the model complexity of our procedure is increased, the variance tends to increase and the squared bias tends to decrease. The opposite behavior occurs as the model complexity is decreased. For k-nearest neighbors, the model complexity is controlled by k.
Typically we would like to choose our model complexity to trade bias off with variance in such a way as to minimize the test error

	El término de varianza es simplemente la varianza de un promedio aquí, y disminuye como el inverso de k. Entonces, como k varía, hay una compensación de sesgo-varianza. En términos más generales, a medida que aumenta la complejidad del modelo de nuestro procedimiento, la varianza tiende a aumentar y la tendencia al cuadrado tiende a disminuir. El comportamiento opuesto ocurre a medida que se reduce la complejidad del modelo. Para k vecinos más cercanos, la complejidad del modelo está controlada por k.
	Por lo general, nos gustaría elegir la complejidad de nuestro modelo para cambiar el sesgo con la varianza de forma que se minimice el error de prueba.
	
	
[MACHINE LEARNING TOM MITCHELL]

In many cases it is important to evaluate the performance of learned hypotheses as precisely as possible. One reason is simply to understand whether to use the hypothesis. For instance, when learning from a limited-size database indicating the effectiveness of different medical treatments, it is important to understand as precisely as possible the accuracy of the learned hypotheses. A second reason is that evaluating hypotheses is an integral component of many learning methods. For example, in post-pruning decision trees to avoid overfitting, we must evaluate the impact of possible pruning steps on the accuracy of the resulting decision tree. Therefore it is important to understand the likely errors inherent in estimating the accuracy of the pruned and unpruned tree. 
Estimating the accuracy of a hypothesis is relatively straightforward when data is plentiful. However, when we must learn a hypothesis and estimate its future accuracy given only a limited set of data, two key difficulties arise:

	En muchos casos, es importante evaluar el rendimiento de las hipótesis aprendidas de la forma más precisa posible. Una razón es simplemente para saber si usar la hipótesis. Por ejemplo, al aprender de una base de datos de tamaño limitado que indica la efectividad de diferentes tratamientos médicos, es importante comprender con la mayor precisión posible la exactitud de las hipótesis aprendidas. Una segunda razón es que la evaluación de hipótesis es un componente integral de muchos métodos de aprendizaje. Por ejemplo, en los árboles de decisión posteriores a la poda para evitar el sobreajuste, debemos evaluar el impacto de los posibles pasos de poda en la precisión del árbol de decisión resultante. Por lo tanto, es importante comprender los probables errores inherentes a la estimación de la precisión del árbol podado y no podado.
	Estimar la precisión de una hipótesis es relativamente sencillo cuando los datos son abundantes. Sin embargo, cuando debemos aprender una hipótesis y estimar su precisión futura con solo un conjunto limitado de datos, surgen dos dificultades clave:

Bias in the estimate. First, the observed accuracy of the learned hypothesis over the training examples is often a poor estimator of its accuracy over future examples. Because the learned hypothesis was derived from these examples, they will typically provide an optimistically biased estimate of hypothesis accuracy over future examples. This is especially likely when the learner considers a very rich hypothesis space, enabling it to overfit the training examples. To obtain an unbiased estimate of future accuracy, we typically test the hypothesis on some set of test examples chosen independently of the training examples and the hypothesis

	Sesgo en la estimación. En primer lugar, la precisión observada de la hipótesis aprendida a través de los ejemplos de entrenamiento es a menudo una mala estimación de su exactitud sobre futuros ejemplos. Debido a que la hipótesis aprendida se derivó de estos ejemplos, típicamente proporcionarán una estimación optimista sesgada de la precisión de la hipótesis sobre ejemplos futuros. Esto es especialmente probable cuando el alumno considera un espacio de hipótesis muy rico, lo que le permite sobreajustar los ejemplos de entrenamiento. Para obtener una estimación no sesgada de la precisión futuro, por lo general, probar la hipótesis de un conjunto de ejemplos de prueba elegido independientemente de los ejemplos de entrenamiento y la hipótesis

	
Variance in the estimate. Second, even if the hypothesis accuracy is measured over an unbiased set of test examples independent of the training examples, the measured accuracy can still vary from the true accuracy, depending on the makeup of the particular set of test examples. The smaller the set of test examples, the greater the expected variance

	Varianza en la estimación. En segundo lugar, incluso si la precisión de la hipótesis se mide en un conjunto imparcial de ejemplos de prueba independientes de los ejemplos de entrenamiento, la precisión medida puede variar de la precisión real, dependiendo de la configuración del conjunto particular de ejemplos de prueba. Cuanto menor es el conjunto de ejemplos de prueba, mayor es la varianza esperada


































