Although most of machine learning practitioners are probably familiar with various techniques for estimating the prediction errors (simple division of data into training/validation sets, cross-validations, etc.), what is not as widely understood is that the evaluation process itself is an error-prone process and that there are multiple contributing ‘components’ to prediction errors.

Aunque la mayoría de los practicantes de aprendizaje automático están probablemente familiarizados con diversas técnicas para estimar los errores de predicción (división simple de datos en conjuntos de entrenamiento / validación, validaciones cruzadas, etc.), lo que no se entiende tan bien es que el proceso de evaluación en sí es proceso propenso a errores y que hay múltiples 'componentes' que contribuyen a los errores de predicción.

Prediction errors of machine learned models have three different components -- noise, bias and variance. Here, we’ll give a brief and relatively math-free description for each one.

Los errores de predicción de los modelos aprendidos en máquina tienen tres componentes diferentes: ruido, polarización y varianza. Aquí, daremos una descripción breve y relativamente libre de matemáticas para cada uno.

Irreducible Noise

The noise here is defied as the noise of the label for data points that have the same features. As an example, say that you want to predict the stock price changes of companies and you are given a small number of features.

Aquí se desafía el ruido como el ruido de la etiqueta para los puntos de datos que tienen las mismas características. Como ejemplo, supongamos que quiere predecir los cambios en el precio de las acciones de las empresas y le otorgan un pequeño número de funciones.

Given this dataset, predicting stock_delta for the fist two rows will always result in errors no matter how accurate the model is since the features can’t distinguish between these two data points.

Dado este conjunto de datos, predecir el delta de valores para las dos primeras filas siempre dará como resultado errores, sin importar cuán preciso sea el modelo, ya que las características no pueden distinguir entre estos dos puntos de datos.

I.e., noise of the error represents the ‘irreducible’ component of the generalization error -- no matter how hard you try, your model can’t perform better (with lower error) than this. This happens for problems where fundamental noise exist in the true distributions of labels/features.

Es decir, el ruido del error representa el componente "irreducible" del error de generalización: no importa cuánto lo intente, su modelo no puede funcionar mejor (con un error menor) que este. Esto sucede para problemas donde existe ruido fundamental en las distribuciones verdaderas de etiquetas / características.

Therefore, estimating what the lower bound of a model’s prediction accuracy can help data scientists in exploration. It could be largely a waste of time to try to improve a model when it is at or near the lower bound of the generalization error.

Por lo tanto, estimar cuál es el límite inferior de la precisión de predicción de un modelo puede ayudar a los científicos de datos en la exploración. En gran medida, puede ser una pérdida de tiempo intentar mejorar un modelo cuando se encuentra en el límite inferior del error de generalización o cerca del mismo.

One important thing to note here, however, is that the noise for a given set of features may not really be noise in the true distribution. It is possible that given more features, for instance, the fist two rows could be distinguished. In such cases, it ‘may’ be that we simply don’t have enough features in the dataset to model the true distributions.

Sin embargo, una cosa importante a tener en cuenta aquí es que el ruido para un conjunto dado de características puede no ser realmente ruido en la distribución verdadera. Es posible que, dadas más características, por ejemplo, se puedan distinguir las dos primeras filas. En tales casos, es posible que simplemente no tengamos suficientes características en el conjunto de datos para modelar las distribuciones verdaderas.

Bias. ‘underfiting’.

Most of prediction models are functions that take in inputs (features) and then spit out an output (prediction). However, it’s important to know that these functions restrict how the output prediction is computed from the input features.

La mayoría de los modelos de predicción son funciones que toman entradas (características) y luego escuchan una salida (predicción). Sin embargo, es importante saber que estas funciones restringen cómo se calcula la predicción de salida a partir de las características de entrada.

For instance, take a linear regression model and assume that all the input features are numbers. A linear regression model can only predict output values that can be computed as:

Por ejemplo, tome un modelo de regresión lineal y suponga que todas las características de entrada son números. Un modelo de regresión lineal solo puede predecir valores de salida que se pueden calcular como:

f(x) =b1 * x1 + b2 * x2 + ... + b0

where x1, x2, … are the input feature values and b0, b1, b2, … are the ‘parameters’ of the model. It is clear from the above equation then that the possible predictions for the linear regression model is limited to weighted sum of input features.

donde x1, x2, ... son los valores de característica de entrada y b0, b1, b2, ... son los 'parámetros' del modelo. De la ecuación anterior se desprende que las posibles predicciones para el modelo de regresión lineal están limitadas a la suma ponderada de las características de entrada.

Such a model may still be reasonably accurate if the output can be approximated as a linear sum. However, if there are signifiantly non-linear relationships between the features and the output (for instance, say, the true relationship involves conditionals, such as ‘if x1 is less than 1 and x2 is greater than 2, then output is 11, …), this will always result in errors no matter how well we can train models or even if we have an infiite number of data points.

Tal modelo aún puede ser razonablemente preciso si la salida se puede aproximar como una suma lineal. Sin embargo, si hay relaciones significativamente no lineales entre las características y el resultado (por ejemplo, la verdadera relación implica condicionales, como 'si x1 es menor que 1 yx2 es mayor que 2, entonces la salida es 11, ... ), esto siempre dará como resultado errores, sin importar qué tan bien podamos entrenar modelos o incluso si tenemos un número infinito de puntos de datos.

Such errors are called ‘bias’ of the model. Intuitively, these errors are the results of the machine learned model not being able to represent the true relationship between the features and the outputs, because of limits on ‘forms’ of calculations the model can perform.

Tales errores se llaman 'sesgo' del modelo. Intuitivamente, estos errores son los resultados del modelo de máquina aprendida que no puede representar la verdadera relación entre las características y los resultados, debido a los límites en las "formas" de cálculos que puede realizar el modelo.

Estimation Bias

A more detailed look into bias reveals that it’s often the model ‘estimation’ bias that inflences prediction errors in the real world. ‘Estimation’ bias (in some cases referred to as induction bias) refers to the fact that models generated by machine learning algorithms in practice only cover a subset of all possible confiurations of the model type. I.e., the algorithm itself restricts the model confiurations that can be learned.

Una mirada más detallada al sesgo revela que a menudo es el sesgo de "estimación" del modelo el que integra los errores de predicción en el mundo real. El sesgo de "estimación" (en algunos casos denominado sesgo de inducción) se refiere al hecho de que los modelos generados por los algoritmos de aprendizaje automático en la práctica solo cubren un subconjunto de todas las confiuraciones posibles del tipo de modelo. Es decir, el algoritmo mismo restringe las confiuraciones del modelo que se pueden aprender.

For instance, take the ridge regression algorithm. Technically, this is also a linear regression ‘learner’ that has a restriction called ‘L2 regularizer’. I.e., the output ‘form’ is still the same as ordinary linear regression models. However, the training is performed to satisfy the following ‘optimization’:

Por ejemplo, tome el algoritmo de regresión de cresta. Técnicamente, este es también un "aprendiz" de regresión lineal que tiene una restricción llamada "regularizador L2". Es decir, la 'forma' de salida sigue siendo la misma que los modelos de regresión lineal ordinarios. Sin embargo, el entrenamiento se realiza para satisfacer la siguiente 'optimización':

Although this may look intimidating, all it’s saying is that in addition to minimizing the MSE (Mean Squared Error) of the label, it also wants to reduce the vector ‘magnitude’ of the coeffients (weights). The tradeof between MSE minimization and coeffient ‘magnitude’ minimization is controlled through an additional user defied parameter.

Aunque esto puede parecer intimidatorio, todo lo que se dice es que, además de minimizar el MSE (Mean Squared Error) de la etiqueta, también quiere reducir la "magnitud" del vector de los coeficientes (pesos). El comercio entre la minimización de MSE y la minimización de la magnitud de los coeficientes se controla a través de un parámetro adicional definido por el usuario.

Although the model’s ‘form’ is the same as the models generated by the ordinary linear regression algorithm, the above algorithm in fact confies the possible coeffients that can be learned to much smaller ranges (whereas ordinary linear regression doesn’t). Therefore, this can further increase the bias component of the prediction error.

Aunque la 'forma' del modelo es la misma que la de los modelos generados por el algoritmo de regresión lineal ordinario, el algoritmo anterior en realidad limita los posibles coeficientes que se pueden aprender a rangos mucho más pequeños (mientras que la regresión lineal ordinaria no lo hace). Por lo tanto, esto puede aumentar aún más el componente de sesgo del error de predicción.

This additional bias introduced by the ‘algorithm’, compared to the bias of the ‘representation’ is called estimation bias or induction bias. A lot of machine learning algorithms introduce estimation biases in practice.

Este sesgo adicional introducido por el "algoritmo", en comparación con el sesgo de la "representación" se denomina sesgo de estimación o sesgo de inducción. Muchos algoritmos de aprendizaje automático introducen sesgos de estimación en la práctica.

Variance. ‘overfiting’.

This is perhaps the most talked about and often the dominant component of prediction errors. Variance error is what people refer to as ‘overfiting’ (whereas bias is known as ‘underfiting’), and it refers to the error introduced by models that learn ‘too much’ from the given dataset.

Este es quizás el componente más comentado ya menudo dominante de los errores de predicción. El error de varianza es lo que las personas llaman "exceso de capacidad" (mientras que el sesgo se conoce como "infrautilización"), y se refiere al error introducido por los modelos que aprenden "demasiado" del conjunto de datos dado.

The notion of variance in prediction error is closely related to variance of samples in statistics. A dataset one has for training models is often just a ‘sample’ of the underlying ‘true’ data. As an example, say that the world has exactly 50% males and 50% females. If we choose 1000 people randomly from the world population, then it’s highly unlikely that we will get exactly 500 males and 500 females.

La noción de varianza en el error de predicción está estrechamente relacionada con la varianza de las muestras en las estadísticas. Un conjunto de datos que uno tiene para los modelos de entrenamiento a menudo es solo una 'muestra' de los datos 'verdaderos' subyacentes. Como ejemplo, supongamos que el mundo tiene exactamente el 50% de hombres y el 50% de mujeres. Si elegimos 1000 personas al azar de la población mundial, entonces es muy poco probable que obtengamos exactamente 500 hombres y 500 mujeres.

It’s possible, for instance, we might end up with 600 males and 400 females, among many other possibilities. If our goal was to ‘learn’ the ratio between males and females in the world from the 1000 sample points, then there’s a very good chance we will end up with an error.

Es posible, por ejemplo, que podamos terminar con 600 hombres y 400 mujeres, entre muchas otras posibilidades. Si nuestro objetivo era 'aprender' la relación entre hombres y mujeres en el mundo a partir de los 1000 puntos de muestra, entonces hay una gran posibilidad de que terminemos con un error.

The exact same thing happens when building prediction models. The training dataset is just a sample of the true data, as mentioned earlier. The error due to variance happens when the training dataset label/feature distributions are different from the true distributions and when the model trainer learns too ‘eagerly’ to predict correctly on the somewhat incorrect training dataset.

Lo mismo ocurre cuando construimos modelos de predicción. El conjunto de datos de entrenamiento es solo una muestra de los datos verdaderos, como se mencionó anteriormente. El error debido a la variación ocurre cuando las etiqueta del conjunto de datos de entrenamiento/las distribuciones de características son diferentes de las distribuciones verdaderas y cuando el modelo que entrena aprende demasiado "ansiosamente" para predecir correctamente en el conjunto de datos de entrenamiento un tanto incorrecto.


Estimating Prediction Errors

In the previous post, we described how three diffrent error components may contribute to the overall prediction errors. Here, we will cover diffrent methods of estimating prediction errors and its noise, bias, and variance. Estimating the prediction error and its noise, bias and variance is a statistic estimation problem where simple approaches may yield incorrect estimates.

En la publicación anterior, describimos cómo tres componentes de error diferentes pueden contribuir a los errores de predicción generales. Aquí, cubriremos diferentes métodos para estimar los errores de predicción y su ruido, sesgo y varianza. La estimación del error de predicción y su ruido, sesgo y varianza es un problema de estimación estadística donde los enfoques simples pueden arrojar estimaciones incorrectas.

For instance, one of the most popular approaches to estimating prediction errors is to divide up the given dataset into a training dataset and a validation dataset. However, if we only do this once, then luck may play a signifiant role in our estimation.

Por ejemplo, uno de los enfoques más populares para estimar los errores de predicción es dividir el conjunto de datos dado en un conjunto de datos de capacitación y un conjunto de datos de validación. Sin embargo, si solo hacemos esto una vez, entonces la suerte puede jugar un papel significativo en nuestra estimación.

First, in such scenarios, we are essentially training a model on a single sample and validating the model on a single sample. Then there’s a chance that, if the prediction estimation comes out to be very good, it was luck and that against new dataset, it’ll perform poorly. For example, it may be that the validation sample and the training sample are both very diffrent from the true distributions and yet similar to each other.

En primer lugar, en tales escenarios, esencialmente estamos entrenando un modelo en una sola muestra y validando el modelo en una sola muestra. Entonces existe la posibilidad de que, si la estimación de predicción es muy buena, fue una suerte y que contra un nuevo conjunto de datos, no funcionará bien. Por ejemplo, puede ser que la muestra de validación y la muestra de entrenamiento sean muy diferentes de las distribuciones verdaderas y, sin embargo, similares entre sí.

There are several approaches that one can use to mitigate such ‘luck’ playing a signifiant role in this. A relatively easy way, particularly with the abundance of data nowadays, is simply to use a lot more training data points and a lot more validation data points. The law of large numbers dictates that our estimates will be more accurate and less ‘lucky’ with larger sample sizes.

Hay varios enfoques que uno puede usar para mitigar tal "suerte" desempeñando un papel significativo en esto. Una forma relativamente fácil, particularmente con la abundancia de datos hoy en día, es simplemente usar muchos más puntos de datos de capacitación y muchos más puntos de datos de validación. La ley de las grandes cantidades dicta que nuestras estimaciones serán más precisas y menos "afortunadas" con tamaños de muestra más grandes.

If drawing larger samples is not plausible, there are various resampling strategies (cross-validations, bootstrapping, etc.) that yield much more accurate estimates of prediction errors. Additionally, resampling strategy is a viable way of estimating bias and variance of prediction errors.

Si no es plausible extraer muestras más grandes, existen varias estrategias de remuestreo (validaciones cruzadas, arranque, etc.) que arrojan estimaciones mucho más precisas de los errores de predicción. Además, la estrategia de remuestreo es una forma viable de estimar el sesgo y la varianza de los errores de predicción.

Estimating Bias, Variance, and Noise

When we mention that prediction errors have bias, variance and noise components, it’s important to note that we are talking about ‘on-the-average’ behavior of the models that have been trained with diffrent samples of the same sizes.

Cuando mencionamos que los errores de predicción tienen componentes de sesgo, varianza y ruido, es importante tener en cuenta que estamos hablando del comportamiento 'en el promedio' de los modelos que han sido entrenados con muestras diferentes de los mismos tamaños.

E.g., if we train just one model on a training sample, it may turn out that the training sample is a very close approximation of the true data and the model we trained has very low overfiting error. However, for the other 99 training samples, the overfiting errors may be high. Variance in ML prediction is this variance of errors across multiple training samples.

Por ejemplo, si entrenamos solo un modelo en una muestra de entrenamiento, puede resultar que la muestra de entrenamiento sea una aproximación muy cercana de los datos verdaderos y el modelo que entrenamos tenga un error de sobreajuste muy bajo. Sin embargo, para las otras 99 muestras de entrenamiento, los errores de sobreajuste pueden ser altos. La varianza en la predicción de ML es esta variación de errores en múltiples muestras de entrenamiento.

Finding this ‘average’ error prediction is important since we usually don’t know whether we are lucky with our training sample draw or not.

Encontrar esta predicción de error "promedio" es importante ya que generalmente no sabemos si tenemos suerte con nuestro sorteo de muestra de capacitación o no.

One way we can estimate bias and variance is through resampling techniques. E.g. we can bootstrap training samples repeatedly and use OOB (out of bag) samples to estimate their average predictions and subsequently compute bias and variance of the predictions (for mathematical defiitions in case of linear regression, go here (page 223, equation 7.9)).

Una forma en que podemos estimar el sesgo y la varianza es mediante técnicas de remuestreo. P.ej. podemos arrancar muestras de entrenamiento repetidamente y usar muestras OOB (fuera de bolsa) para estimar sus predicciones promedio y posteriormente calcular el sesgo y la varianza de las predicciones (para defiiciones matemáticas en caso de regresión lineal, vaya aquí (página 223, ecuación 7.9)).

Such resampling techniques are expensive computationally since they involve training models many times on the same dataset. Moreover, often one wants to measure bias/variance breakdowns across diffrent models or diffrent hyperparameters. However, with the availability of large clusters of machines nowadays, it’s not an impractical proposition any more.

Tales técnicas de remuestreo son costosas desde el punto de vista computacional, ya que implican modelos de capacitación muchas veces en el mismo conjunto de datos. Además, a menudo se desea medir desviaciones de sesgo / varianza a través de modelos diferentes o hiperparámetros diferentes. Sin embargo, con la disponibilidad de grandes grupos de máquinas hoy en día, ya no es una proposición poco práctica.

Error Measures and Bias, Variance, and Noise

Figuring out how bias, variance and noise add up to the overall prediction error is a challenge in itself. It turns out that this also depends on how the prediction errors are ‘measured’.

Averiguar cómo el sesgo, la varianza y el ruido se suman al error de predicción general es un desafío en sí mismo. Resulta que esto también depende de cómo se "miden" los errores de predicción.

For example, if the errors are measured in MSE (Mean Squared Error), then the average prediction error is additive. I.e. :

Por ejemplo, si los errores se miden en MSE (Mean Squared Error), entonces el error promedio de predicción es aditivo. Es decir. :

PredErr =irreducible noise + bias2 +variance

(Exact mathematical defiition is here (page 223, equation 7.9))

What this means is that, in case of regression, we can guarantee reduction of the overall prediction error through bias reduction, variance reduction, or both.

Lo que esto significa es que, en caso de regresión, podemos garantizar la reducción del error de predicción global mediante la reducción del sesgo, la reducción de la varianza o ambas.

However, if we measure the error through mis-classifiation rate, as in many classifiation problems, the effct of individual component on the overall prediction error is in fact non-linear. For example, classifiation errors can be shown to be:

Sin embargo, si medimos el error a través de la tasa de clasificación errónea, como en muchos problemas de clasificación, el efecto del componente individual en el error de predicción global es, de hecho, no lineal. Por ejemplo, se puede mostrar que los errores de clasificación son:

MisclassifiationErr =c1*irreducible noise + bias + c2*variance

where c1 depends on the proportion of correctly classifid data points and incorrectly classifid data points for the same features, and c2 depends on bias. (Exact mathematical defiition can be found in this paper (page 24))

donde c1 depende de la proporción de puntos de datos correctamente clasificados y puntos de datos incorrectamente clasificados para las mismas características, y c2 depende del sesgo. (La defiición matemática exacta se puede encontrar en este documento (página 24))

Intuitively, this is because with classifiation errors, ‘wrongly right prediction’ is possible. E.g., if there’s noise in the labels, then incorrectly predicting on a data point whose label is diffrent from the ‘consensus label’ can mitigate the overall noise contribution. For example, say, we have a set of feature values and 60% of times, its label comes out to be one. The remaining 40% of times, the label for those feature values comes out to be zero. Then, we can defie the misclassifiation noise to be 2 / 5 for this set of feature values.

Intuitivamente, esto se debe a que con los errores de clasificación, es posible una "predicción equivocadamente correcta". Por ejemplo, si hay ruido en las etiquetas, la predicción incorrecta en un punto de datos cuya etiqueta es diferente de la "etiqueta de consenso" puede mitigar la contribución general al ruido. Por ejemplo, digamos que tenemos un conjunto de valores de características y un 60% de veces, su etiqueta sale como una. El 40% restante de las veces, la etiqueta para esos valores de características sale a cero. Entonces, podemos desafiar el ruido de clasificación errónea para que sea 2/5 para este conjunto de valores de características.

Intuitivamente, esto se debe a que con los errores de clasificación, es posible una "predicción equivocadamente correcta". Por ejemplo, si hay ruido en las etiquetas, la predicción incorrecta en un punto de datos cuya etiqueta es diferente de la "etiqueta de consenso" puede mitigar la contribución general al ruido. Por ejemplo, digamos que tenemos un conjunto de valores de características y un 60% de veces, su etiqueta sale como una. El 40% restante de las veces, la etiqueta para esos valores de características sale a cero. Entonces, podemos desafiar el ruido de clasificación errónea para que sea 2/5 para este conjunto de valores de características.

Now, if we train a model on a random training sample and its prediction is always 1, then the contribution from the noise to the average prediction error would be unchanged at 2 / 5. However, if the prediction sometimes comes out as 1 on some training data, and sometimes comes out as 0 on diffrent training data, then the noise contributes to the error only when the prediction is 1.

Ahora, si entrenamos un modelo en una muestra de entrenamiento aleatorio y su predicción es siempre 1, entonces la contribución del ruido al error promedio de predicción se mantendría sin cambios en 2 / 5. Sin embargo, si la predicción a veces aparece como 1 en algunos datos de entrenamiento, y a veces sale como 0 en diferentes datos de entrenamiento, entonces el ruido contribuye al error solo cuando la predicción es 1.

Likewise, if there’s error due to the bias of the model (the average prediction for a feature set is diffrent from the consensus label), then the error due to overfiting may in fact reduce the overall error since a diffrent prediction from the average prediction may in fact be the correct classifiation.

Del mismo modo, si hay un error debido al sesgo del modelo (la predicción promedio para un conjunto de características es diferente de la etiqueta de consenso), entonces el error debido a la sobrefatización puede de hecho reducir el error general ya que una predicción diferente de la predicción promedio de hecho, sea la clasificación correcta.

The overall classifiation error rate can still be reduced by reducing bias and/or variance. However, their relationships to the overall error rate are not linear as in the MSE models.

La tasa de error de clasificación general aún se puede reducir al reducir el sesgo y / o la varianza. Sin embargo, sus relaciones con la tasa de error general no son lineales como en los modelos MSE.

Model Selection and Data Size

In model selection, estimating bias and variance is especially useful. Knowing whether the prediction errors we are getting are due to bias or variance can lead us to explore proper models (e.g., if the errors are mostly bias, then we can explore high variance, low bias models. If the errors are mostly variance, then we can explore low variance, high bias models.)

En la selección del modelo, estimar el sesgo y la varianza es especialmente útil. Saber si los errores de predicción que recibimos se deben a sesgo o varianza nos puede llevar a explorar modelos adecuados (por ejemplo, si los errores son principalmente sesgo, entonces podemos explorar modelos de alta varianza y sesgo bajo. Si los errores son mayormente varianza, entonces podemos explorar modelos de baja varianza y alto sesgo).

In a ‘big data’ world, high variance, low bias models are often preferred. This is because the larger the dataset size is, the smaller the variance of error will be. This is because there’s a better chance that the dataset would more closely resemble the underlying distribution the larger the dataset is. As the size of the dataset goes to infinity, the variance would entirely disappear.

En un mundo de 'big data', a menudo se prefieren los modelos de alta varianza y bajo sesgo. Esto se debe a que cuanto mayor es el tamaño del conjunto de datos, menor será la varianza del error. Esto se debe a que hay una mayor probabilidad de que el conjunto de datos se parezca más a la distribución subyacente cuanto mayor sea el conjunto de datos. Como el tamaño del conjunto de datos va a infinito, la varianza desaparecería por completo.

In contrast, the bias is irreducible even if one has a lot of data points. Intuitively, this makes sense since bias is due to the fundamental restrictions on the ‘form’ of the output calculations. If the true underlying relationship between features and the prediction can’t be represented by the model, it’ll always have the bias error, even with an infiite amount of data points.

Por el contrario, el sesgo es irreductible incluso si uno tiene muchos puntos de datos. Intuitivamente, esto tiene sentido ya que el sesgo se debe a las restricciones fundamentales sobre la 'forma' de los cálculos de salida. Si el modelo no puede representar la verdadera relación subyacente entre las características y la predicción, siempre tendrá el error de sesgo, incluso con una cantidad infiita de puntos de datos.

The notion of ‘big’ is, however, also dependent on the problem domain. E.g., 10 million data points may be relatively small in image/speech/NLP domains, whereas they may be plentiful in a preference prediction problem with only a dozen features or so.

La noción de "grande" es, sin embargo, también depende del dominio del problema. Por ejemplo, 10 millones de puntos de datos pueden ser relativamente pequeños en dominios de imagen / voz / PNL, mientras que pueden ser abundantes en un problema de predicción de preferencias con solo una docena de características más o menos.

Examples of high variance models may be:
• linear model with a large number of features that include many expanded features (such as polynomial expansion).
• Decision-trees without bounds on their sizes.
• Deep neural networks.

Ejemplos de modelos de alta varianza pueden ser:
• modelo lineal con una gran cantidad de características que incluyen muchas características expandidas (como la expansión polinómica).
• Árboles de decisión sin límites en sus tamaños.
• Redes neuronales profundas.

Model Selection through Bias-Variance Tradeoff

A lot of times, there’s a trade-of relationship between bias and variance components of prediction errors. E.g., when one reduces the bias of a prediction error, there’s a good chance that the variance of the error would go up. When one reduces the variance, the bias tends to go up. The job of a data scientist often comes down to fiding the ‘optimal’ balance between bias and variance to minimize the overall error rate.

Muchas veces, hay una relación de intercambio entre los componentes de varianza y sesgo de los errores de predicción. Por ejemplo, cuando uno reduce el sesgo de un error de predicción, hay una buena probabilidad de que la varianza del error suba. Cuando uno reduce la varianza, el sesgo tiende a subir. El trabajo de un científico de datos a menudo se reduce a buscar el equilibrio "óptimo" entre el sesgo y la varianza para minimizar la tasa de error general.

Intuitively, this is because bias and variance are both related to flxibility (or complexity) of models. The more flxible (or complex) a model is, the smaller its bias would be since the model might be able to induce any relationship between label and features from a training sample. But at the same time, such flexible models would typically ‘eager-fi’ to any training sample, giving a high variance error. Vice versa is also true for inflexible models.

Intuitivamente, esto se debe a que el sesgo y la varianza están relacionados con la flexibilidad (o complejidad) de los modelos. Cuanto más flexible (o complejo) sea un modelo, menor será su sesgo, ya que el modelo podría inducir cualquier relación entre la etiqueta y las características de una muestra de capacitación. Pero, al mismo tiempo, dichos modelos flexibles normalmente estarían "ajuste ansioso" para cualquier muestra de entrenamiento, lo que daría un alto error de varianza. Viceversa también es cierto para modelos inflexibles.

The act of hyper-parameter search and feature selection (such as fiding optimal for regularized models, fiding the optimal tree depths, fiding the proper number of features, etc.) is precisely the act of fiding the optimal balance between bias and variance.

El acto de la búsqueda de hiperparámetros y la selección de características (como el óptimo para modelos regularizados, la profundización óptima del árbol, el número adecuado de características, etc.) es precisamente el acto de buscar el equilibrio óptimo entre el sesgo y la varianza.

Ensemble models that achieve the best of both worlds 

There are ensemble techniques that are capable of ‘getting the best of both worlds’. The most famous one is Random Forest. It is based on ‘averaging’
predictions of multiple decorrelated trees that are individually highly overfit. It turns out that because individual trees are highly overfi, the overall model’s bias is very low to begin with. And by adding up and averaging many trees’ predictions that are diffrent from each other, the variance can be reduced without increasing bias! In some counterintuitive fashion, this is a technique where adding more complexities to a model can actually decrease both bias and variance.

Hay técnicas de conjunto que son capaces de "obtener lo mejor de ambos mundos". El más famoso es Random Forest. Se basa en 'promediar'
predicciones de múltiples árboles descorrelacionados que están individualmente altamente sobreajustados. Resulta que debido a que los árboles individuales están muy sobreendeudados, el sesgo general del modelo es muy bajo para empezar. ¡Y al sumar y promediar las predicciones de muchos árboles que son diferentes entre sí, la varianza puede reducirse sin aumentar el sesgo! De alguna manera intuitiva, esta es una técnica donde agregar más complejidades a un modelo en realidad puede disminuir tanto el sesgo como la varianza.

There is also a recently developed variant of deep neural network called drop-out network that leverages a similar idea and has been shown to perform extremely well.

También hay una variante recientemente desarrollada de red neuronal profunda llamada red de abandono que aprovecha una idea similar y se ha demostrado que funciona extremadamente bien.

As a side note, one thing people often seem to get confused about is the diffrence between Random Forest and boosting. Whereas Random Forest can reduce both bias and variance as described above, boosting is an ensemble technique where one starts with a weak, very high-bias and low-variance model and as more ‘weak’ models are added, the overall ensemble moves to a lower-bias and higher-variance state. Therefore, one still has to search for the optimal balance between bias and variance with boosting, whereas with Random Forest, one can often indefiitely add more trees to reduce variance without increasing bias (the error reduction would flatten after a certain number of trees, but it’ll not go back up with more trees).

Como nota al margen, una cosa que la gente a menudo parece confundirse es la diferencia entre Random Forest y el boosting. Mientras que Random Forest puede reducir tanto el sesgo como la varianza como se describió anteriormente, boosting es una técnica ensemble donde se comienza con un modelo débil, de muy alto sesgo y de baja varianza y cuando se agregan más modelos "débiles", el conjunto general se mueve a un estado de menor sesgo y mayor varianza. Por lo tanto, todavía hay que buscar el equilibrio óptimo entre sesgo y varianza con refuerzo, mientras que con Random Forest, a menudo se pueden agregar indefinidamente más árboles para reducir la varianza sin aumentar el sesgo (la reducción de error se aplanaría después de un cierto número de árboles, pero no volverá a subir con más árboles).

This is one of the reasons that Random Forest is extremely popular, since one can get highly accurate models without a lot of ‘parameter-search’ as he/she has to do with other models. (However, there are still certain parameters that need to be tweaked, such as the number of random features to be searched per node, and it turns out that this can still affct ‘bias/variance’ of the model).

Esta es una de las razones por las que Random Forest es extremadamente popular, ya que uno puede obtener modelos muy precisos sin una gran cantidad de "búsqueda de parámetros", ya que tiene que ver con otros modelos. (Sin embargo, todavía hay ciertos parámetros que deben modificarse, como el número de funciones aleatorias que se buscarán por nodo, y resulta que esto todavía puede afectar a la "sesgo / varianza" del modelo).

Resumen:

La varianza en la predicción de ML es esta variación de errores en múltiples muestras de entrenamiento.
