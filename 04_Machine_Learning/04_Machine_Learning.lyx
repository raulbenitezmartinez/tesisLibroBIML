#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\begin_preamble
\renewcommand{\listtablename}{Indice de tablas}
\renewcommand{\tablename}{Tabla} 
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language spanish
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize 12
\spacing double
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 1.5cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Machine Learning
\end_layout

\begin_layout Standard
El objetivo de este capítulo es visualizar qué aspectos de Machine Learning
 fueron tomados como componentes de solución al problema de estudio.
\end_layout

\begin_layout Standard
En lo que va de la Edad Contemporánea el hombre siente fuertemente la necesidad
 de encontrar respuestas a ciertos aspectos de sus propias capacidades.
 Respuestas de cómo funciona el cerebro humano, cómo se van originando e
 hilando los pensamientos, cómo se va adquiriendo el conocimiento, cómo
 la racionalidad está presente en las decisiones humanas, cuál es el mecanismo
 de toma de decisiones de la mente humana, cómo utiliza su inteligencia
 para resolver problemas e ideas abstractas, cuál es el proceso que sigue
 la mente para poder aprender, interrogantes sobre la memoria del cerebro
 y cómo los sentidos van alimentando de percepciones para tener una visión
 única del universo.
 La ciencias de la computación ha abierto la puerta a las respuestas.
\end_layout

\begin_layout Standard
En 1950 Alan Turing dio uno de los saltos más importantes al proponer el
 enfoque de su 
\begin_inset Quotes eld
\end_inset

Prueba de Turing
\begin_inset Quotes erd
\end_inset

, donde un computador es considerado como agente inteligente si un evaluador
 humano, sin interactuar con el computador, realiza preguntas y no es capaz
 de distinguir si las respuestas vienen de una persona o del computador.
 En su artículo 
\begin_inset Quotes eld
\end_inset

Computing Machinery and Intelligence
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "CMIAlan1950"

\end_inset

 expuso este y otros conceptos y como tal es considerado padre de la Inteligenci
a Artificial.
\end_layout

\begin_layout Standard
Aunque hoy en día aún es válida la Prueba de Turing, el desafío no está
 en construir un agente inteligente total, sino mas bien buscar que un computado
r tenga capacidades como 
\begin_inset CommandInset citation
LatexCommand cite
key "IAEModerno2"

\end_inset

:
\end_layout

\begin_layout Enumerate
Procesamiento del lenguaje natural
\end_layout

\begin_layout Enumerate
Representación del conocimiento
\end_layout

\begin_layout Enumerate
Razonamiento automático
\end_layout

\begin_layout Enumerate
Aprendizaje automático (Machine Learning)
\end_layout

\begin_layout Enumerate
Visión computacional
\end_layout

\begin_layout Enumerate
Robótica
\end_layout

\begin_layout Standard
Entre los precursores de IA están John McCarthy, Marvin Minsky, Allen Newell
 y Herbert Simon, todos ganadores del premio 
\begin_inset Quotes eld
\end_inset

ACM A.M.
 Turing Award
\begin_inset Quotes erd
\end_inset

 por sus notables aportes en los inicios de IA.
 McCarthy acuño el término Artificial Intelligence en el taller 
\begin_inset Quotes eld
\end_inset

Dartmouth Summer Research Project on Artificial Intelligence
\begin_inset Quotes erd
\end_inset

 que organizó y se desarrolló en junio del año 1956.
 En palabras transcriptas, el taller perseguía el siguiente objetivo: 
\shape italic

\begin_inset Quotes eld
\end_inset

El estudio debe proceder sobre la base de la conjetura de que cada aspecto
 del aprendizaje o cualquier otra característica de la inteligencia puede,
 en principio, describirse tan precisamente que se puede hacer que una máquina
 lo simule.
 Se intentará encontrar cómo hacer que las máquinas usen el lenguaje, formen
 abstracciones y conceptos, resuelvan tipos de problemas ahora reservados
 para los humanos y se mejoren a sí mismos.
 Creemos que se puede lograr un avance significativo en uno o más de estos
 problemas si un grupo de científicos cuidadosamente seleccionados trabajan
 juntos durante un verano
\begin_inset Quotes erd
\end_inset


\shape default
.
 Entre los aportes mas destacado de McCarthy se pueden mencionar la definición
 del lenguaje de alto nivel Lisp, la creación del tiempo compartido y el
 artículo 
\begin_inset Quotes eld
\end_inset

Programs with Common Sense
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "PCSMc1959"

\end_inset

 donde define su Generador de Consejos, todos estos aportes desarrollados
 en 1958.
 Minsky diseñó SNARC (Stochastic Neural Analog Reinforcement Calculator)
 la primera máquina a partir de una red neuronal, en el año 1951, junto
 a Seymour Papert publicó el libro 
\begin_inset Quotes eld
\end_inset

Perceptrons: an introduction to computational geometry
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "PercepMinsPape1987"

\end_inset

 en el año 1969 y también creó un modelo de redes semánticas denominadas
 
\begin_inset Quotes eld
\end_inset

marcos
\begin_inset Quotes erd
\end_inset

 publicado en 
\begin_inset Quotes eld
\end_inset

A framework for representing knowledge
\begin_inset Quotes erd
\end_inset

 en el año 1974 
\begin_inset CommandInset citation
LatexCommand cite
key "FrameMinsky1974"

\end_inset

.
\end_layout

\begin_layout Standard
En setiembre de 1956 en el 
\begin_inset Quotes eld
\end_inset

MIT Symposium on Information Theory
\begin_inset Quotes erd
\end_inset

 se mostraron trabajos muy importantes como el de George Miller que presentó
 
\begin_inset Quotes eld
\end_inset

The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity
 for Processing Information
\begin_inset Quotes erd
\end_inset

, Noam Chomsky presentó 
\begin_inset Quotes eld
\end_inset

Three Models for the Description of Language
\begin_inset Quotes erd
\end_inset

, y Allen Newell y Herbert Simon presentaron 
\begin_inset Quotes eld
\end_inset

The Logic Theory Machine
\begin_inset Quotes erd
\end_inset

: programa de computador capaz de hacer la demostración de un teorema y
 considerado el primer programa de IA.
 El campo de la ciencia cognitiva echó sus raíces en este simposio evidenciando
 que los modelos informáticos se pueden utilizar para modelar la psicología
 de la memoria, el lenguaje y el pensamiento lógico.
 En 1959 presentaron el programa 
\begin_inset Quotes eld
\end_inset

General Problem Solver
\begin_inset Quotes erd
\end_inset

 (GPS), pretendía funcionar como una máquina universal para resolver problemas
 y fue el primer programa de computador que separó su conocimiento de los
 problemas (reglas representadas como datos de entrada) de su estrategia
 de cómo resolver problemas (un motor de resolución genérico).
\end_layout

\begin_layout Standard
Machine Learning como subcampo de IA está presente en muchas aplicaciones
 de la vida real, especialmente en aquellas donde se requiere el procesamiento
 de grandes cantidades de datos.
 Por esta razón la tecnología de la información la toma como aliado esencial.
 Muchos avances tecnológicos de última generación utilizan algoritmos de
 Machine Learning para realizar un análisis inteligente de los datos 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
 Entre algunas aplicaciones conocidas se destacan:
\end_layout

\begin_layout Itemize
Reconocimiento de rostros de Facebook
\end_layout

\begin_layout Itemize
Kinect para Xbox 360
\end_layout

\begin_layout Itemize
Gafas de realidad virtual
\end_layout

\begin_layout Itemize
Voice reconigtion en smartphones
\end_layout

\begin_layout Itemize
La tecnología del habla y el campo relacionado del reconocimiento de caracteres
 manuscritos
\end_layout

\begin_layout Itemize
Motores de búsqueda, sistemas de recomendación, y los sistemas para la construcc
ión de portales Web
\end_layout

\begin_layout Itemize
STRIPS (Fikes y Nilsson, 1971), el primero de los grandes sistemas de planificac
ión
\end_layout

\begin_layout Itemize
Robot Shakey
\end_layout

\begin_layout Itemize
Robot dogs con sistemas de reconocimiento de voz
\end_layout

\begin_layout Itemize
Recomender system en plataformos como Amazon, Netflix, Facebook 
\end_layout

\begin_layout Itemize
Reconocimiento automático de ciertas áreas en el mundo realizado por satélites
\end_layout

\begin_layout Standard
Para recalcar el veloz crecimiento de los datos en el mundo, en un estudio
 publicado por la International Data Corporation (IDC) y patrocinado por
 DELL EMC que se denomina: 
\begin_inset Quotes eld
\end_inset

The Digital Universe in 2020: Big Data, Bigger Digital Shadows, and Biggest
 Growth in the Far East
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "DUGrow2012"

\end_inset

 se analiza qué tan rápido crecen los datos cada año, una medida que incluyen
 todos los datos digitales creados, replicados y consumidos en un solo año.
 En la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:IDC-exabyes"

\end_inset

 se muestra una proyección del tamaño hasta el 2020.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename recursos/THE DIGITAL UNIVERSE IN 2020.png
	scale 70

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:IDC-exabyes"

\end_inset

Del 2005 al 2020 el universo digital crecerá en un factor de 300, de 130
 exabytes a 40,000 exabytes, es decir se duplicará cada dos años.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
El universo digital analizado está compuesto por imágenes y videos en teléfonos
 móviles cargados en YouTube, películas digitales, datos bancarios en cajeros
 automáticos, imágenes de seguridad en aeropuertos y en eventos importantes
 como los Juegos Olímpicos, colisiones subatómicos registradas por el Gran
 Colisionador de Hadrones en el CERN, llamadas de voz a través de líneas
 telefónicas digitales y los mensajes de texto.
 Las mediciones indican que en el 2005 existían 130 exabytes en datos digitales,
 en el 2010 llegó a 1200 exabytes, en el 2015 a unos 7900 exabytes y para
 el 2020 se pronostica que llegará a los 40000 exabytes.
 IDC estima que para 2020, hasta el 33% del universo digital contendrá informaci
ón que podría ser valiosa si se analiza 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:IDC-exabyes"

\end_inset

.
\end_layout

\begin_layout Section
Definición
\end_layout

\begin_layout Standard
En 1959 Arthur Samuel en una publicación escribió: 
\shape italic

\begin_inset Quotes eld
\end_inset

Programming computers to learn from experience should eventually eliminate
 the need for much of this detailed programming effort
\begin_inset Quotes erd
\end_inset


\shape default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Arthur1959"

\end_inset

.
 Este pionero ya presagiaba que los programas, a partir del aprendizaje
 sobre datos históricos (la experiencia), podrían efectuar tareas de toma
 de decisiones sin ser programadas explícitamente dichas decisiones.
 Samuel desarrolló en el año 1952 programas que aprendían a jugar Damas
 y los cuales aprendían su propia función de evaluación.
 En el año 1959 desarrolló programas que aprendían a jugar Ajedrez.
\end_layout

\begin_layout Standard
Samuel define como sigue: 
\shape italic

\begin_inset Quotes eld
\end_inset

Machine Learning es un campo de estudio que da a las computadoras la capacidad
 de aprender sin ser explícitamente programadas
\begin_inset Quotes erd
\end_inset


\shape default
.
 Otro investigador, Tom Mitchell propuso en 1998 la siguiente definición:
 
\shape italic

\begin_inset Quotes eld
\end_inset

Well posed Learning Problem: A computer program is said to learn from experience
 E with respect to some task T and some performance measure P, if its performanc
e on T, as measured by P, improves with experience E
\begin_inset Quotes erd
\end_inset


\shape default
.
 Donde se nos indica que el aprendizaje en las máquinas deberá ser parecido
 al aprendizaje en los humanos, por ejemplo cuando una criatura comienza
 a hablar a través de la experiencia de pronunciar las palabras y de su
 interacción con otras personas, entonces sucede que su capacidad de hablar
 se va perfeccionando o mejorando.
\end_layout

\begin_layout Standard
* Machine Learning como sub campo de IA.
 Qué es Machine Learning.
\end_layout

\begin_layout Standard
- Definición de Arthur Samuel - Definición de John McCarthy - Agentes inteligent
es - Elementos de accion - Elemento de aprendizaje - Mejores decisiones
 - Tipo de realimentación - Estado actual y acciones - Propiedades del mundo
 y percepciones - Evolución del mundo - Información de utilidad y estados
 deseables - Información acción-valor y acciones deseables - Metas y estados
 que maximizan utilidad
\end_layout

\begin_layout Standard

\shape italic
\begin_inset Quotes eld
\end_inset

The purpose of machine learning is to learn from training data in order
 to make as good as possible predictions on new, unseen, data
\begin_inset Quotes erd
\end_inset


\shape default

\begin_inset CommandInset citation
LatexCommand cite
key "Jean2016"

\end_inset

.
 La dificultad radica en que debemos construir modelos que nos acerquen
 a una buena predicción sobre datos aún no conocidos o imprevistos.
 Peter Prettenhofer y Gille Louppe presentan la siguiente definición:
\end_layout

\begin_layout Standard
Data comes as...
\end_layout

\begin_layout Itemize
A set of examples 
\begin_inset Formula $\left\{ \left(x_{i},y_{i}\right)\mid0\leq i<n\;samples\right\} $
\end_inset

, with
\end_layout

\begin_deeper
\begin_layout Itemize
Feature vector 
\begin_inset Formula $x\in\mathbb{R}^{n\;features}$
\end_inset

, and
\end_layout

\begin_layout Itemize
Response 
\begin_inset Formula $y\in\mathbb{R}$
\end_inset

(regression) or 
\begin_inset Formula $y\in\left\{ -1,1\right\} $
\end_inset

 (classification)
\end_layout

\end_deeper
\begin_layout Itemize
Goal is to...
\end_layout

\begin_deeper
\begin_layout Itemize
Find a function 
\begin_inset Formula $ŷ=f\left(x\right)$
\end_inset


\end_layout

\begin_layout Itemize
Such that error 
\begin_inset Formula $L\left(y,ŷ\right)$
\end_inset

on new (unseen) 
\begin_inset Formula $x$
\end_inset

 is minimal
\end_layout

\end_deeper
\begin_layout Section
Formas de Aprendizaje 
\end_layout

\begin_layout Standard
Los algoritmos de aprendizaje automático se pueden agrupar según la forma
 en que se realiza el aprendizaje, pero teniendo en cuenta que todos reciben
 un conjunto de ejemplos del cuál aprender.
 Uno de los componentes más importantes al momento de diagnosticar la naturaleza
 del problema de aprendizaje es el tipo de retroalimentación disponible
 para el aprendizaje.
 Hay tres tipos distintos de aprendizaje: supervisado, no supervisado y
 por refuerzo 
\begin_inset CommandInset citation
LatexCommand citet
key "IAEModerno2"

\end_inset

.
\end_layout

\begin_layout Subsection
Aprendizaje supervisado
\end_layout

\begin_layout Standard
En los problemas de apredizaje supervisado los algoritmos reciben como entrada
 datos de entrenamiento que ya tienen resultados conocidos o etiquetas.
 En el caso más general un instructor provee el valor correcto de la salida
 de cada ejemplo.
 Como resultado se aprende una función a partir de las entradas y salidas
 de los ejemplos.
 Como ejemplo de aplicación están los vehículos autoconducidos que deben
 aprender a diferenciar una calle de la que no es (salida booleana es calle
 o no es calle), también debe aprender a frenar (salida booleana frenar
 o no frenar), etc.
 Example problems are classification and regression para Supervised Learning.
 Example algorithms include Logistic Regression and the Back Propagation
 Neural Network.
\end_layout

\begin_layout Standard
El problema de estudio en cuestión utiliza algoritmos de aprendizaje supervisado
, donde el experto en compras da la respuesta correcta a cada ejemplo.
\end_layout

\begin_layout Standard
* Aprendizaje supervisado
\end_layout

\begin_layout Standard
- Agente aprende - Aprender una función - Ejemplos, sus entradas y salidas
 - Regla condición-acción (frenar o no frenar) - Aprender función (contiene
 la imagen un autobús?) - Aprender función, estado actual, acciones - Aprendizaj
e inductivo - Valores correctos, función desconocida - Ejemplos de f, función
 verdadera - Función h, hipótesis aproxima f - Espacio de hipótesis - Función
 computable, máquina de Turing - Arboles de decisiones - Compromiso expresividad
 espacio hipótesis-complejidad h sencillas y consistentes
\end_layout

\begin_layout Subsection
Aprendizaje no supervisado
\end_layout

\begin_layout Standard
En los problemas de apredizaje no supervisado los algoritmos reciben como
 entrada datos de entrenamiento que no tienen resultados conocidos o etiquetas.
 Se buscan estructuras presentes y como resultado se pueden extraer reglas
 generales, o reducir sistemáticamente la redundancia, o se pueden organizar
 los datos por similitud.
 Se aprende a partir de patrones de entrada de los que no se dispone de
 sus valores de salida, es decir 
\shape italic
a priori
\shape default
 no hay etiquetas o respuesta correcta en los ejemplos.
 Como ejemplo de aplicación está el caso de la computadora que aprendió
 sola el concepto de un animal gato.
 Example problems are clustering, dimensionality reduction and association
 rule learning para Unsupervised Learning.
 Example algorithms include: the Apriori algorithm and k-Means.
\end_layout

\begin_layout Standard
* Aprendizaje no supervisado
\end_layout

\begin_layout Standard
- Agente de aprendizaje no supervisado - Aprender patrones de entradas -
 Valores de salidas no especificados - Ejemplo no etiquetados (dias tráfico
 bueno y malo) - Estado deseable no desconocido a priori - Acción correcta
 desconocida a priori - Naive Bayes - Métodos de aprendizaje paramétrico
 - Aprendizaje basado en instancias - Redes neuronales - Máquinas de vectores
 soporte (SVMs) o máquinas núcleo - Reconocimiento de dígitos
\end_layout

\begin_layout Subsection
Aprendizaje por refuerzo
\end_layout

\begin_layout Standard
El problema del aprendizaje por refuerzo es el más general de las tres categoría
s.
 En vez de que un instructor indique al agente qué hacer, el agente de aprendiza
je por refuerzo debe aprender a partir del refuerzo o recompensa.
 Por ejemplo, la falta de propina al final del viaje (o una gran factura
 por golpear la parte trasera del coche de delante) da al agente algunas
 indicaciones de que su comportamiento no es el deseable.
 El aprendizaje por refuerzo típicamente incluye el subproblema de aprender
 cómo se comporta el entorno.
\end_layout

\begin_layout Standard
* Aprendizaje por refuerzo
\end_layout

\begin_layout Standard
- Agentes que aprenden a partir refuerzo - Aprender comportamiento del entorno
 - Modelo del entorno (completo o no tan completo) - Función de recompensa
 - Ningún conocimiento a priori - Juego nuevo, reglas desconocidas (al final
 del juego, perdiste o ganaste) - Aprendizaje por refuerzo pasivo - Aprendizaje
 por refuerzo activo (exploración, aprendizaje-q) - Aproximacion de funciones
 - Aplicaciones a juegos - Aplicaciones a control de robots - Búsqueda de
 la política - Diseño global del agente - Diseños basados en el modelo -
 Diseños de modelo libre - Diseños reactivos
\end_layout

\begin_layout Section
Algoritmos de Machine Learning
\end_layout

\begin_layout Standard
El Dr.
 Jason Brownlee es un especialista en aprendizaje automático, desarrollador,
 escritor y empresario.
 Ha trabajado en sistemas de aprendizaje automático para la defensa, startups
 y pronósticos meteorológicos.
 Tiene una comunidad en https://machinelearningmastery.com/, la cual empezó
 porque le apasiona ayudar a los desarrolladores profesionales a comenzar
 y aplicar con confianza el Machine Learning que les permita resolver problemas
 complejos.
 Los algoritmos de aprendizaje automático se pueden agrupar según la similaridad
 en términos de su forma o función, como por ejemplo los métodos basados
 en árboles y los métodos inspirados en redes neuronales.
 Se muestra en la Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Algoritmos-de-machine"

\end_inset

 lo propuesto por el Dr.
 Jason:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename recursos/MachineLearningAlgorithms.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Algoritmos-de-machine"

\end_inset

Clasificación de los algoritmos según
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
No hay un consenso general de cómo agrupar los algoritmos de Machine Learning
 en términos de su función o de cómo trabajan.
 La Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Algoritmos-de-machine"

\end_inset

 mostró un método útil de agrupación, que no es perfecto y ni exhaustivo
 en los grupos y algoritmos.
 Hay algoritmos que pueden encajar en varias categorías como Learning Vector
 Quantization que es a la vez un método inspirado en una red neuronal y
 un método basado en instancia.
 También hay categorías que tienen el mismo nombre que describen el problema
 y la clase de algoritmo como Regression y Clustering.
 Se podría manejar estos casos listando los algoritmos dos veces o insertando
 en el grupo al que subjetivamente se ajusta mejor.
 Se utiliza este último enfoque de no duplicar algoritmos.
\end_layout

\begin_layout Subsection
Algoritmos de regresión
\end_layout

\begin_layout Standard
Los Algoritmos de Regresión (Regression Algorithms) modelan la relación
 que existe entre variables, se mejora iterativamente utilizando una medida
 de error en las predicciones hechas por el modelo.
 Los métodos de regresión son herramientas de las estadísticas que se han
 adoptado en el aprendizaje de la máquina.
 Podemos utilizar el término regresión para referirnos a la clase de problema
 y también a la clase de algoritmo.
 Para ser más exactos, la regresión es realmente un proceso.
\end_layout

\begin_layout Subsection
Algoritmos basados en instancia
\end_layout

\begin_layout Standard
El modelo de aprendizaje Basado en Instancia (Instance Based) es un problema
 de decisión con instancias o ejemplos de datos de entrenamiento que se
 consideran importantes o requeridos para el modelo.
 Estos métodos típicamente construyen una base de datos con ejemplos y los
 compara con los nuevos datos utilizando una medida de similaridad para
 así encontrar la mejor coincidencia y hacer la predicción.
 Por esta razón, los métodos basados en la instancia también se llaman métodos
 de aprendizaje basado en memoria.
 El enfoque se pone en la representación de las instancias almacenadas y
 las medidas de similaridad utilizadas entre instancias.
\end_layout

\begin_layout Subsection
Algoritmos de regularización
\end_layout

\begin_layout Standard
Los Algoritmos de Regularización (Regularization), comprende una extensión
 hecha a otros métodos (típicamente a los métodos de regresión).
 Penaliza los modelos basándose en sus complejidades, favoreciendo modelos
 más simples que también son mejores de generalizar.
 Son populares, potentes y en general simples modificaciones de otros métodos.
\end_layout

\begin_layout Subsection
Algoritmos de árboles de decisión
\end_layout

\begin_layout Standard
Los métodos de Árboles de Decisión (Decision Tree) construyen un modelo
 de decisiones hechas en base a los valores de atributos en los datos.
 Las decisiones se bifurcan en la estructura del árbol hasta que se tome
 una decisión de predicción para un registro dado.
 Los árboles de decisión son entrenados en los datos para problemas de clasifica
ción y regresión.
 Los árboles de decisión son a menudo rápidos y precisos y un gran favorito
 en aprendizaje automático.
\end_layout

\begin_layout Subsection
Algoritmos bayesianos
\end_layout

\begin_layout Standard
Los métodos Bayesianos (Bayesian) son los que aplican explícitamente el
 teorema de Bayes para problemas tales como la clasificación y la regresión.
\end_layout

\begin_layout Subsection
Algoritmos de agrupación
\end_layout

\begin_layout Standard
La Agrupación (Clustering) así como también la regresión describen la clase
 de problema y la clase de método.
 Los métodos de agrupación suelen estar organizados según el enfoque del
 modelado, tales como los basados en centroides y los jerárquicos.
 Todos los métodos atañen a la utilización de las estructuras inherentes
 en los datos, para organizar dichos datos de la mejor manera posible en
 grupos de máxima uniformidad.
\end_layout

\begin_layout Subsection
Algoritmos de aprendizaje de reglas de asociación
\end_layout

\begin_layout Standard
Los métodos de aprendizaje de Reglas de Asociación (Rule System) extraen
 reglas que mejor explican las relaciones observadas entre variables en
 los datos.
 Estas reglas pueden descubrir asociaciones importantes y comercialmente
 útiles, en grandes conjuntos de datos multidimensionales que pueden ser
 explotados por una organización.
\end_layout

\begin_layout Subsection
Algoritmos de redes neurales artificiales
\end_layout

\begin_layout Standard
Las Redes Neuronales artificiales (Neural Networks) son modelos inspirados
 en la estructura y/o función de las redes neuronales biológicas.
 Son una clase de búsqueda de patrones que se utilizan comúnmente para problemas
 de regresión y clasificación.
 Es realmente un enorme subcampo compuesto de cientos de algoritmos y variacione
s para todo tipo de tipos de problemas.
 Se ha separado el aprendizaje profundo de las redes neuronales debido a
 su enorme crecimiento y popularidad.
\end_layout

\begin_layout Subsection
Algoritmos de aprendizaje profundo
\end_layout

\begin_layout Standard
Los métodos de Aprendizaje Profundo (Deep Learning) son una moderna actualizació
n de las redes neuronales artificiales que explotan el abundante y barato
 poder de computación.
 Se ocupan en construir redes neuronales mucho más grandes y complejas y,
 muchos métodos se refieren a problemas de aprendizaje semi-supervisados
 donde grandes conjuntos de datos contienen muy pocos datos etiquetados.
\end_layout

\begin_layout Subsection
Algoritmos de reducción de dimensionalidad
\end_layout

\begin_layout Standard
Al igual que los métodos de agrupación, la Reducción de la Dimensionalidad
 (Dimensionality Reduction) busca y explora la estructura inherente en los
 datos, pero en este caso de una manera no supervisada o en orden a resumir
 o describir los datos utilizando menos información.
 Esto puede ser útil para visualizar datos dimensionales o para simplificar
 datos que luego se pueden utilizar en un método de aprendizaje supervisado.
 Muchos de estos métodos pueden ser adaptados para su uso en clasificación
 y regresión.
\end_layout

\begin_layout Subsection
Algoritmos ensamble
\end_layout

\begin_layout Standard
Métodos de Ensamble (Ensemble) son modelos compuestos por múltiples modelos
 más débiles, que son entrenados independientemente y cuyas predicciones
 son combinadas de alguna manera para hacer la predicción general.
 Mucho esfuerzo se pone en qué tipos de aprendices débiles combinar y las
 formas en que hay que combinarlos.
 Esta es una clase de técnica muy poderosa y como tal es muy popular.
\end_layout

\begin_layout Subsection
Otros algoritmos
\end_layout

\begin_layout Standard
Algoritmos no lineales como:
\end_layout

\begin_layout Itemize
Support Vector Machines
\end_layout

\begin_layout Standard
Algoritmos para tareas especiales en el proceso del aprendizaje automático:
\end_layout

\begin_layout Itemize
Feature selection algorithms 
\end_layout

\begin_layout Itemize
Algorithm accuracy evaluation 
\end_layout

\begin_layout Itemize
Performance measures
\end_layout

\begin_layout Standard
Algoritmos para subcampos de especialidad de aprendizaje automático:
\end_layout

\begin_layout Itemize
Computational intelligence (evolutionary algorithms, etc.)
\end_layout

\begin_layout Itemize
Computer Vision (CV)
\end_layout

\begin_layout Itemize
Natural Language Processing (NLP)
\end_layout

\begin_layout Itemize
Recommender Systems
\end_layout

\begin_layout Itemize
Reinforcement Learning
\end_layout

\begin_layout Itemize
Graphical Models
\end_layout

\begin_layout Section
Problemas de clasificación y regresión
\end_layout

\begin_layout Standard
En los problemas de clasificación el modelo creado debe predecir la clase,
 tipo o categoría de la salida.
\end_layout

\begin_layout Standard
La gama de problemas de aprendizaje es claramente grande, como vimos al
 discutir aplicaciones.
 Dicho esto, los investigadores han identificado un número cada vez mayor
 de plantillas que se pueden usar para abordar un gran conjunto de situaciones.
 Son esas plantillas las que facilitan el despliegue del aprendizaje automático
 en la práctica y nuestra discusión se centrará en gran medida en un conjunto
 de elección de tales problemas.
 Ahora ofrecemos una lista completa de plantillas.
\end_layout

\begin_layout Subsection
Clasificación binaria
\end_layout

\begin_layout Standard
En su forma más simple se reduce a la siguiente cuestión: dado un patrón
 
\begin_inset Formula $x$
\end_inset

 extraído de un dominio 
\begin_inset Formula $X$
\end_inset

, estimar qué valor asumirá una variable aleatoria binaria asociada 
\begin_inset Formula $y\in\left\{ \pm1\right\} $
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
\end_layout

\begin_layout Standard
La clasificación binaria es probablemente el problema más estudiado en el
 aprendizaje automático y ha dado lugar a una gran cantidad de desarrollos
 algorítmicos y teóricos importantes durante el siglo pasado.
 En su forma más simple, se reduce a la pregunta: dado un patrón x extraído
 de un dominio X, estimar qué valor asumirá una variable aleatoria binaria
 asociada y ∈ {± 1}.
\end_layout

\begin_layout Standard
Por ejemplo, si se muestran imágenes de manzanas y naranjas, podemos indicar
 si el objeto en cuestión es una manzana o una naranja.
 Igualmente bien, podríamos querer predecir si un propietario de vivienda
 podría incumplir su préstamo dado sus datos de ingresos y su historial
 de crédito, o si un correo electrónico determinado es spam o jamón.
 La capacidad de resolver este problema básico ya nos permite abordar una
 gran variedad de configuraciones prácticas.
 Existen muchas variantes con respecto al protocolo en el que estamos obligados
 a hacer nuestra estimación:
\end_layout

\begin_layout Subsection
Clasificación multiclase
\end_layout

\begin_layout Standard
Es la extensión lógica de la clasificación binaria.
 La principal diferencia es que ahora 
\begin_inset Formula $y\in\left\{ 1,2,3..,N\right\} $
\end_inset

 puede asumir un rango de valores diferentes 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
 El problema de estudio en cuestión utiliza clasificación multiclase, donde
 
\begin_inset Formula $y\in\left\{ Nada,Poco,Medio,Mucho\right\} $
\end_inset

.
 Por ejemplo, es posible que deseemos clasificar un documento de acuerdo
 con el idioma en que fue escrito (inglés, francés, alemán, español, hindi,
 japonés, chino, ...).
 
\end_layout

\begin_layout Standard
La principal diferencia con anterioridad es que el costo del error puede
 depender en gran medida del tipo de error que cometamos.
 Por ejemplo, en el problema de evaluar el riesgo de cáncer, hace una diferencia
 significativa si clasificamos erróneamente una etapa temprana del cáncer
 como saludable (en cuyo caso es probable que el paciente muera) o una etapa
 avanzada de cáncer (en en qué caso es probable que el paciente sufra molestias
 por un tratamiento excesivamente agresivo).
\end_layout

\begin_layout Subsection
Regression
\end_layout

\begin_layout Standard
Es otra aplicación prototípica.
 Aquí el objetivo es estimar una variable de valor real y ∈ R dado un patrón
 x (ver, por ejemplo, la Figura 1.7).
 Por ejemplo, podríamos querer estimar el valor de un stock al día siguiente,
 el rendimiento de un fabuloso semiconductor dado el proceso actual, el
 contenido de hierro de las mediciones de espectroscopia de masas dadas
 por el mineral o la frecuencia cardíaca de un atleta, dada la información
 del acelerómetro.
 Una de las cuestiones clave en las que los problemas de regresión difieren
 entre sí es la elección de una pérdida.
 Por ejemplo, al estimar los valores de stock, nuestra pérdida para una
 opción de venta será decididamente unilateral.
 Por otro lado, a un deportista aficionado solo le importaría que nuestra
 estimación de la frecuencia cardíaca coincida con la media real.
\end_layout

\begin_layout Section
Modelado de clasificación multiclase 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset


\end_layout

\begin_layout Standard
Para desarrollar un modelo o esquema de machine learning para resolver problemas
 de clasificación multiclase, es necesario conocer los componentes esenciales
 que la forman.
\end_layout

\begin_layout Subsection
Ejemplos o instancias
\end_layout

\begin_layout Standard
La entrada de un esquema de aprendizaje automático es un conjunto de instancias.
 Estas instancias son las cosas que deben ser clasificadas, asociadas o
 agrupadas.
 En el escenario estándar, cada instancia es un ejemplo individual e independien
te del concepto que se debe aprender.
 Para el problema de estudio el proceso de Business Intelligence es quien
 provee las instancias.
\end_layout

\begin_layout Subsection
Características o atributos
\end_layout

\begin_layout Standard
Las instancias son caracterizadas mediante los valores de un conjunto predetermi
nado de atributos.
 Cada instancia proporciona una entrada al aprendizaje automático y es caracteri
zado por los valores de un conjunto fijo y predefinido de características
 o atributos.
\end_layout

\begin_layout Subsection
Etiquetas
\end_layout

\begin_layout Standard
Las cantidades nominales tienen valores que son símbolos distintos.
 Los valores mismos sirven como etiquetas o nombres, de ahí el término nominal,
 que viene de la palabra latina para nombre.
 Los atributos nominales a veces se llaman categorizados, enumerados o discretos.
\end_layout

\begin_layout Subsection
Conjunto de entrenamiento
\end_layout

\begin_layout Standard
El grupo de ejemplos utilizados en el proceso de entrenamiento de los algoritmos
 de aprendizaje automático constituyen el conjunto de entrenamiento.
\end_layout

\begin_layout Subsection
Algoritmos de clasificación multiclase
\end_layout

\begin_layout Standard
Constituye el conjunto de algoritmos de machine que soportan problemas de
 clasificación multiclase.
\end_layout

\begin_layout Standard
Hipótesis, Parámetros, Función de costo, Objetivo.
\end_layout

\begin_layout Standard
Funcion Objetivo (f), Variables de entrada (X), Variable de salida (Y).
 Y = f(X)
\end_layout

\begin_layout Subsection
Conjunto de prueba
\end_layout

\begin_layout Standard
Para predecir el rendimiento de un clasificador sobre nuevos datos, necesitamos
 evaluar su tasa de error en un conjunto de datos que no desempeñó ningún
 papel en la formación del clasificador.
 Este conjunto de datos independiente se denomina conjunto de prueba.
\end_layout

\begin_layout Section
Algoritmos de clasificación en Weka
\end_layout

\begin_layout Standard
Weka es una colección de algoritmos de aprendizaje automático para tareas
 de minería de datos.
 Los algoritmos pueden ser aplicados directamente a un conjunto de datos
 o llamados desde código Java.
 Weka contiene herramientas para pre-procesamiento de datos, clasificación,
 regresión, clustering, reglas de asociación y visualización.
 También es adecuado para desarrollar nuevos esquemas de aprendizaje automático
 
\begin_inset CommandInset citation
LatexCommand citet
key "Weka3"

\end_inset

.
 En el problema de estudio se utiliza el conjunto de algoritmos de clasificación
 de Weka 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2016"

\end_inset

.
 Los algoritmos de clasificación de Weka que se utilizarán son los siguientes
 
\begin_inset CommandInset citation
LatexCommand cite
key "WekaCla"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="43" columns="3">
<features islongtable="true" longtabularalignment="center">
<column alignment="left" valignment="top" width="3.5cm">
<column alignment="left" valignment="top" width="6.3cm">
<column alignment="left" valignment="top" width="5.5cm">
<row caption="true">
<cell multicolumn="1" alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Clasificadores-Weka"

\end_inset

Clasificadores Weka
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multicolumn="2" alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Categoría del clasificador
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Nombre del clasificador
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Modelo, técnica o algoritmo que implementa
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores bayesianos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
BayesNet
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Bayes Network (Red Bayesiana) 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "WekaMan3-8-0"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores bayesianos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
NaiveBayes
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Naive Bayes 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "John1995"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores bayesianos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
NaiveBayesMultinomial
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Naive Bayes multinomial 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Mccallum1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores bayesianos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
NaiveBayesMultinomialUpdateable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Naive Bayes multinomial actualizable 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Mccallum1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores bayesianos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
NaiveBayesUpdateable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Naive Bayes actualizable 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "John1995"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Basado en funciones
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Logistic
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Regresión Logística 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "leCessie1992"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Basado en funciones
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
MultilayerPerceptron
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Red Neuronal con 
\shape italic
back propagation
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Basado en funciones
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
SimpleLogistic
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Regresión Logística lineal con LogitBoost 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Landwehr2005"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citet
key "Sumner2005"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Basado en funciones
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
SMO
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sequential Minimal Optimization con Support Vector 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Platt1998"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citet
key "Keerthi2001"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citet
key "Hastie1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores perezosos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
IBk
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
K-nearest neighbours (K vecinos más cercanos) 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Aha1991"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores perezosos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
KStar
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
K* con función de distancia basada en entropía 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Cleary1995"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificadores perezosos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
LWL
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Locally Weighted Learning (Aprendizaje Ponderado Localmente) 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Frank2003"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citet
key "Atkeson1996"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
AdaBoostM1
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Adaboost M1 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Freund1996"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
AttributeSelectedClassifier
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Selección de atributos
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Bagging
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Bagging 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Breiman1996"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
ClassificationViaRegression
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Métodos de regresión 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Frank1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
CVParameterSelection
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Selección de parámetros 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Kohavi1995"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
FilteredClassifier
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Filtro arbitrario
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
IterativeClassifierOptimizer
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Optimización del número de iteraciones
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
LogitBoost
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Regresión Logística aditiva 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Friedman1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
MultiClassClassifier
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Metaclasificador
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
MultiClassClassifierUpdateable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Metaclasificador actualizable
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
MultiScheme
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Selección del clasificador
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
RandomCommittee
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Conjunto aleatorizado de clasificadores base
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
RandomizableFilteredClassifier
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificador arbitrario con filtro arbitrario
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
RandomSubSpace
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árbol de decisión 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Ho1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Stacking
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Combinación de clasificadores utilizando apilamiento 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Wolpert1992"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Vote
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Combinación de clasificadores 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Kuncheva2004"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citet
key "Kittler1998"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Meta algoritmos
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
WeightedInstancesHandlerWrapper
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Soporte de instancias ponderadas
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sistema de reglas
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
DecisionTable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Tabla de decisión simple 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Kohavi1995a"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sistema de reglas
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
JRip
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
\begin_inset Quotes eld
\end_inset

Repeated Incremental Pruning to Produce Error Reduction
\begin_inset Quotes erd
\end_inset

 (RIPPER) 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Cohen1995"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sistema de reglas
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
OneR
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificador 1R 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Holte1993"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sistema de reglas
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
PART
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Divide y vencerás para construir un árbol de decisión C4.5 parcial 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Frank1998a"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Sistema de reglas
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
ZeroR
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Clasificador 0-R
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
DecisionStump
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Decision stump in conjunction with a boosting algorithm
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
HoeffdingTree
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Algoritmo de inducción incremental del árbol de decisión 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Hulten2001"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
J48
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árbol de decisión C4.5 podado o no podado 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Quinlan1993"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
LMT
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
\begin_inset Quotes eld
\end_inset

Árboles de Modelos Logísticos
\begin_inset Quotes erd
\end_inset

 o 
\begin_inset Quotes eld
\end_inset

Logistic Model Trees
\begin_inset Quotes erd
\end_inset

 (LMT) 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Landwehr2005"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citet
key "Sumner2005"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
RandomForest
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
\begin_inset Quotes eld
\end_inset

Bosque de Árboles Aleatorios
\begin_inset Quotes erd
\end_inset

 o 
\begin_inset Quotes eld
\end_inset

Forest of Random Trees
\begin_inset Quotes erd
\end_inset

 
\size default

\begin_inset CommandInset citation
LatexCommand citet
key "Breiman2001"

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
RandomTree
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Considera K atributos elegidos al azar en cada nodo.
 No realiza poda.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Árboles de decisión
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
REPTree
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\size small
Construye un árbol de decisión/regresión utilizando la información de ganancia/v
arianza
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Section
Evaluación del aprendizaje
\end_layout

\begin_layout Standard
La evaluación es la clave para lograr avances reales en el aprendizaje automátic
o.
 Entre las técnicas de evaluación se destacan la Validación Cruzada (Cross-Valid
ation) y la Validación Cruzada k-pliegues Estratificado (Stratified k-fold
 Cross-Validation).
 
\end_layout

\begin_layout Standard
La técnica de Cross-Validation consiste en dividir los datos en un número
 de pliegues o particiones, si por ejemplo elegimos cuatro, entonces cada
 partición se utiliza para las pruebas y las demás para el entrenamiento,
 al repetir este proceso 4 veces se consigue que cada partición se haya
 utilizado una vez como conjunto de pruebas.
 
\end_layout

\begin_layout Standard
La técnica estándar para predecir la tasa de error es Stratified k-fold
 Cross-Validation, donde la estratificación se refiere al proceso de reorganizar
 los datos de tal manera a asegurar que cada pliegue sea una buena representació
n del conjunto.
 Comúnmente se acepta que 10 es el número de pliegues con el que se obtiene
 la mejor estimación de error, idea basada en diversas pruebas sobre conjuntos
 de datos diferentes y para distintas técnicas de aprendizaje 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
Otra técnica es el Porcentaje de División (Percentage Split) con el que
 puede retener para la prueba un determinado porcentaje de los datos.
 Es una alternativa utilizar un conjunto de pruebas separado o una división
 porcentual de los datos de entrenamiento.
 Si elegimos 60% como porcentaje de división, entonces el conjunto de prueba
 se constituirá con el 40% de las instancias y el conjunto de entrenamiento
 con el 60% de las instancias.
\end_layout

\begin_layout Section
Métricas de desempeño 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset


\end_layout

\begin_layout Standard
Para los problemas de clasificación, es natural medir el rendimiento de
 un clasificador en términos de la tasa de error (error rate).
 El clasificador predice la clase de cada instancia: si es correcta se cuenta
 como un éxito, sino se cuenta como un error.
 La tasa de error es sólo la proporción de errores cometidos sobre un conjunto
 de instancias, y mide el rendimiento general del clasificador.
 Por supuesto, lo que nos interesa es el probable desempeño futuro en nuevos
 datos, no el rendimiento pasado en datos antiguos.
\end_layout

\begin_layout Standard
Para predecir el rendimiento de un clasificador en nuevos datos, necesitamos
 evaluar su tasa de error en un conjunto de datos que no desempeñó ningún
 papel en la formación del clasificador.
 Este conjunto de datos independiente se denomina conjunto de prueba.
 En tales situaciones se suele hablar de tres conjuntos de datos: los datos
 de entrenamiento, los datos de validación y los datos de prueba.
 
\end_layout

\begin_layout Standard
Los datos de entrenamiento son utilizados por uno o más esquemas de aprendizaje
 para conocer clasificadores.
 Los datos de validación se utilizan para optimizar los parámetros de los
 clasificadores, o para seleccionar uno determinado.
 A continuación, los datos de prueba se utilizan para calcular la tasa de
 error del método final optimizado.
 Cada uno de los tres conjuntos debe ser independiente: El conjunto de validació
n debe ser diferente del conjunto de entrenamiento para obtener un buen
 desempeño en la etapa de optimización o selección y el conjunto de pruebas
 debe ser diferente de ambos para obtener una estimación confiable de la
 tasa de error real.
\end_layout

\begin_layout Subsection
Aciertos
\end_layout

\begin_layout Standard
Número de instancias correctamente clasificadas.
\end_layout

\begin_layout Subsection
Porcentaje de Aciertos
\end_layout

\begin_layout Standard
Porcentaje de instancias correctamente clasificadas.
\end_layout

\begin_layout Subsection
Estadística Kappa (Kappa Statistic)
\end_layout

\begin_layout Standard
En problemas de clasificación para aplicaciones reales normalmente los errores
 cuestan diferentes cantidades.
 Por ejemplo en bancos y financieras el costo de prestar a una persona que
 no paga sus deudas es mayor que el costo de rechazar un préstamo a una
 persona que es pagadora.
 Los Verdaderos Positivos (True Positive - TP) y Verdaderos Negativos (True
 Negative - TN) son clasificaciones correctas.
 Un Falso Positivo (False Positive - FP) es cuando el resultado se predice
 incorrectamente como sí (o positivo) cuando es realmente no (o negativo).
 Un Falso Negativo (False Negative - FN) es cuando el resultado se predice
 incorrectamente como negativo cuando es realmente positivo.
 En la predicción multiclase, cada elemento de la matriz de confusión muestra
 el número de ejemplos de prueba para los que la clase real es la fila y
 la clase prevista es la columna.
 Son buenos resultados los grandes números en la diagonal principal e idealmente
 cero fuera de la diagonal principal.
 
\begin_inset Quotes eld
\end_inset

Kappa se utiliza para medir el acuerdo entre la predicción y la observación
 de las categorizaciones de un conjunto de datos, mientras que se corrige
 para un acuerdo que ocurre por casualidad
\begin_inset Quotes erd
\end_inset

.
 Si los evaluadores están totalmente de acuerdo Kappa alcanza un valor máximo
 igual a 1.
 Si no hay total acuerdo entre los evaluadores, entonces Kappa tiene un
 valor 
\begin_inset Formula $<1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\kappa=\frac{Pr\left(a\right)-Pr\left(e\right)}{1-Pr\left(e\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde: 
\begin_inset Formula $Pr\left(a\right)$
\end_inset

 es el acuerdo observado relativo entre los observadores y 
\begin_inset Formula $Pr\left(e\right)$
\end_inset

 es la probabilidad hipotética de acuerdo al azar utilizando los datos observado
s para calcular las probabilidades de que cada observador clasifique aleatoriame
nte cada categoría.
\end_layout

\begin_layout Subsection
Sensibilidad (Recall)
\end_layout

\begin_layout Standard
Calcula la sensibilidad con respecto a una clase en particular, esto se
 define como: positivos correctamente clasificados / positivos totales.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Recall=\frac{TP}{TP+FN}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Precisión (Precision)
\end_layout

\begin_layout Standard
Calcula la precisión con respecto a una clase en particular, esto se define
 como: positivos correctamente clasificados / total predicho como positivo.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Precision=\frac{TP}{TP+FP}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Puntuación-F (F-Measure)
\end_layout

\begin_layout Standard
La Puntuación-F es una medida de la exactitud de una prueba.
 La Puntuación-F puede interpretarse como un promedio ponderado de la precisión
 y sensibilidad, donde alcanza su mejor valor en 1 y el peor en 0.
 Se define como: 2 * Recall * Precision / (Recall + Precision).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
F-Measure=\frac{2*Recall*Precision}{\left(Recall+Precision\right)}
\end{equation}

\end_inset


\end_layout

\end_body
\end_document
