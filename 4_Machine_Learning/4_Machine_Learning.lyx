#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass IEEEtran
\begin_preamble
% Bibliografia en español
\usepackage[fixlanguage]{babelbib}
\selectbiblanguage{spanish}

% Bibliografia
\usepackage[authoryear,square,sort]{natbib}
\bibliographystyle{plainnat}
\bibpunct{[}{]}{,}{a}{}{;}
\renewcommand\cite{\citep}
\end_preamble
\options journal
\use_default_options true
\maintain_unincluded_children false
\language spanish
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 1.5cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Machine Learning
\end_layout

\begin_layout Standard
En 1959 Arthur Samuel en una publicación escribió: 
\shape italic

\begin_inset Quotes eld
\end_inset

Programming computers to learn from experience should eventually eliminate
 the need for much of this detailed programming effort
\begin_inset Quotes erd
\end_inset


\shape default
 
\begin_inset CommandInset citation
LatexCommand cite
key "Arthur1959"

\end_inset

.
 Lo que nos lleva a pensar que uno pioneros de machine learning ya dejaba
 visualizar que los programas, a partir del aprendizaje sobre los datos
 históricos (la experiencia), podrían efectuar tareas de toma de decisiones
 sin ser programadas explícitamente dichas decisiones.
 
\end_layout

\begin_layout Subsection
Definición
\end_layout

\begin_layout Standard
Samuel define machine learning como sigue: 
\shape italic

\begin_inset Quotes eld
\end_inset

Machine Learning es un campo de estudio que da a las computadoras la capacidad
 de aprender sin ser explícitamente programadas
\begin_inset Quotes erd
\end_inset


\shape default
.
 Otro investigador de machine learning Tom Mitchell propuso en 1998 la siguiente
 definición: 
\shape italic

\begin_inset Quotes eld
\end_inset

Well posed Learning Problem: A computer program is said to learn from experience
 E with respect to some task T and some performance measure P, if its performanc
e on T, as measured by P, improves with experience E
\begin_inset Quotes erd
\end_inset


\shape default
.
\end_layout

\begin_layout Standard

\shape italic
\begin_inset Quotes eld
\end_inset

The purpose of machine learning is to learn from training data in order
 to make as good as possible predictions on new, unseen, data
\begin_inset Quotes erd
\end_inset


\shape default

\begin_inset CommandInset citation
LatexCommand cite
key "Jean2016"

\end_inset

.
 La dificultad radica en que debemos construir modelos que nos acerquen
 a una buena predicción sobre datos aún no conocidos o imprevistos.
 Peter Prettenhofer y Gille Louppe presentan la siguiente definición:
\end_layout

\begin_layout Standard
Data comes as...
\end_layout

\begin_layout Itemize
A set of examples 
\begin_inset Formula $\left\{ \left(x_{i},y_{i}\right)\mid0\leq i<n\_samples\right\} $
\end_inset

, with
\end_layout

\begin_deeper
\begin_layout Itemize
Feature vector 
\begin_inset Formula $x\in\mathbb{R}^{n\_features}$
\end_inset

, and
\end_layout

\begin_layout Itemize
Response 
\begin_inset Formula $y\in\mathbb{R}$
\end_inset

(regression) or 
\begin_inset Formula $y\in\left\{ -1,1\right\} $
\end_inset

 (classification)
\end_layout

\end_deeper
\begin_layout Itemize
Goal is to...
\end_layout

\begin_deeper
\begin_layout Itemize
Find a function 
\begin_inset Formula $ŷ=f\left(x\right)$
\end_inset


\end_layout

\begin_layout Itemize
Such that error 
\begin_inset Formula $L\left(y,ŷ\right)$
\end_inset

on new (unseen) 
\begin_inset Formula $x$
\end_inset

 is minimal
\end_layout

\end_deeper
\begin_layout Subsection
Categoría de algoritmos
\end_layout

\begin_layout Standard
Los algoritmos de aprendizaje automático se pueden categorizar según la
 forma en que se realiza el aprendizaje, pero teniendo en cuenta que todos
 reciben un conjunto de ejemplos del que aprender.
\end_layout

\begin_layout Subsubsection
Aprendizaje supervisado (supervised learning): El algoritmo recibe datos
 de entrenamiento que contienen la respuesta correcta para cada ejemplo.
\end_layout

\begin_layout Subsubsection
Aprendizaje no supervisado (unsupervised learning): El algoritmo busca estructur
as en los datos de entrenamiento, como encontrar qué ejemplos son similares
 entre sí, y agruparlos en clusters.
\end_layout

\begin_layout Subsection
Tipos de problemas
\end_layout

\begin_layout Standard
Teniendo en cuenta las clases de problemas que los algoritmos de aprendizaje
 pueden resolver, los tipos de problemas se pueden agrupar como sigue.
\end_layout

\begin_layout Subsubsection
Regresión: Un problema de aprendizaje supervisado donde la respuesta a aprender
 es un valor continuo.
\end_layout

\begin_layout Subsubsection
Clasificación: Un problema de aprendizaje supervisado donde la respuesta
 a aprender es un valor de un conjunto finito de posibles valores discretos.
\end_layout

\begin_layout Subsubsection
Segmentación: Un problema de aprendizaje no supervisado donde la estructura
 a aprender es un conjunto de clusters donde cada cluster tiene similares
 ejemplos.
\end_layout

\begin_layout Subsubsection
Análisis de red: Un problema de aprendizaje no supervisado donde la estructura
 a aprender es información acerca de la importancia y el rol de los nodos
 en una red.
\end_layout

\begin_layout Subsection
Componentes esenciales 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
La entrada de un esquema de aprendizaje automático es un conjunto de instancias
 o ejemplos (examples).
 Estas instancias son las cosas que deben ser clasificadas, asociadas o
 agrupadas.
 Las instancias son caracterizadas mediante los valores de un conjunto predeterm
inado de atributos (features).
 Los ejemplos o instancias utilizadas en el proceso de entrenamiento del
 algoritmo de aprendizaje automático constituye el conjunto de entrenamiento
 (training set).
 Para predecir el rendimiento de un clasificador sobre nuevos datos, necesitamos
 evaluar su tasa de error en un conjunto de datos que no desempeñó ningún
 papel en la formación del clasificador, este conjunto de datos independiente
 se denomina conjunto de prueba (test set).
\end_layout

\begin_layout Subsection
El problema de la clasificación
\end_layout

\begin_layout Standard
En los problemas de clasificación el modelo creado debe predecir la clase,
 tipo o categoría de la salida.
\end_layout

\begin_layout Subsubsection
Clasificación binaria (binary classification): En su forma más simple se
 reduce a la pregunta: dado un patrón x extraído de un dominio X, estimar
 qué valor asumirá una variable aleatoria binaria asociada y ∈ {± 1} 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Clasificación multiclase (multiclass classification): Es la extensión lógica
 de la clasificación binaria.
 La principal diferencia es que ahora y ∈ {1, ...
 , N} puede asumir un rango de valores diferentes 
\begin_inset CommandInset citation
LatexCommand cite
key "IntroML2008"

\end_inset

.
\end_layout

\begin_layout Subsection
Algoritmos de clasificación en WEKA
\end_layout

\begin_layout Standard
Weka es una colección de algoritmos de aprendizaje automático para tareas
 de minería de datos.
 Los algoritmos pueden ser aplicados directamente a un conjunto de datos
 o llamados desde código Java.
 Weka contiene herramientas para pre-procesamiento de datos, clasificación,
 regresión, clustering, reglas de asociación y visualización.
 También es adecuado para desarrollar nuevos esquemas de aprendizaje automático
 
\begin_inset CommandInset citation
LatexCommand cite
key "Weka3"

\end_inset

.
 Los algoritmos de clasificación de Weka que se utilizarán son los siguientes
 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2016"

\end_inset

: BayesNet, NaiveBayes, NaiveBayesUpdateable, Logistic, MultilayerPerceptron,
 SimpleLogistic, SMO, OneR, DecisionTable, JRip, PART, ZeroR, DecisionStump,
 J48, LMT, RandomForest, RandomTree, REPTree.
\end_layout

\begin_layout Subsection
Evaluación de lo aprendido
\end_layout

\begin_layout Standard
La evaluación es la clave para lograr avances reales en el aprendizaje automátic
o.
 Entre las técnicas se destaca la Validación Cruzada (Cross-Validation)
 que consiste dividir los datos en un número de pliegues o particiones.
 Si por ejemplo elegimos cuatro, entonces cada partición se utiliza para
 las pruebas y las demás para el entrenamiento.
 Al repetir este proceso 4 veces se consigue que cada partición se haya
 utilizado una vez como conjunto de pruebas.
 La técnica estándar para predecir la tasa de error es la Validación Cruzada
 Estratificada (Stratified k-fold Cross-Validation).
 La estratificación se refiere al proceso de reorganizar los datos de tal
 manera a asegurar que cada pliegue sea una buena representación del conjunto.
 Comúnmente se acepta que 10 es el número de pliegues con el que se obtiene
 la mejor estimación de error, idea basada en diversas pruebas sobre conjuntos
 de datos diferentes y para distintas técnicas de aprendizaje 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
Otra técnica es el Porcentaje de División (Percentage Split) con el que
 puede retener para la prueba un determinado porcentaje de los datos.
 Es una alternativa utilizar un conjunto de pruebas separado o una división
 porcentual de los datos de entrenamiento.
 Si elegimos 60% como porcentaje de división, entonces el conjunto de prueba
 se constituirá con el 40% de las instancias y el conjunto de entrenamiento
 con el 60% de las instancias.
\end_layout

\begin_layout Subsection
Métricas de desempeño
\end_layout

\begin_layout Standard
Para los problemas de clasificación, es natural medir el rendimiento de
 un clasificador en términos de la tasa de error (error rate).
 El clasificador predice la clase de cada instancia: si es correcta, se
 cuenta como un éxito; sino, es un error.
 La tasa de error es sólo la proporción de errores cometidos sobre un conjunto
 de instancias, y mide el rendimiento general del clasificador.
 Por supuesto, lo que nos interesa es el probable desempeño futuro en nuevos
 datos, no el rendimiento pasado en datos antiguos.
\end_layout

\begin_layout Standard
Para predecir el rendimiento de un clasificador en nuevos datos, necesitamos
 evaluar su tasa de error en un conjunto de datos que no desempeñó ningún
 papel en la formación del clasificador.
 Este conjunto de datos independiente se denomina conjunto de pruebas.
 En tales situaciones, la gente suele hablar de tres conjuntos de datos:
 los datos de entrenamiento, los datos de validación y los datos de prueba.
 Los datos de entrenamiento son utilizados por uno o más esquemas de aprendizaje
 para conocer clasificadores.
 Los datos de validación se utilizan para optimizar los parámetros de los
 clasificadores, o para seleccionar uno determinado.
 A continuación, los datos de prueba se utilizan para calcular la tasa de
 error del método final optimizado.
 Cada uno de los tres conjuntos debe ser independiente: El conjunto de validació
n debe ser diferente del conjunto de entrenamiento para obtener un buen
 desempeño en la etapa de optimización o selección y el conjunto de pruebas
 debe ser diferente de ambos para obtener una estimación confiable de la
 tasa de error real.
\end_layout

\begin_layout Subsubsection
Aciertos: Número de instancias correctamente clasificadas.
\end_layout

\begin_layout Subsubsection
Porcentaje de Aciertos: Porcentaje de instancias correctamente clasificadas.
\end_layout

\begin_layout Subsubsection
Estadística Kappa (Kappa Statistic): En problemas de clasificación para
 aplicaciones reales normalmente los errores cuestan diferentes cantidades.
 Por ejemplo en bancos y financieras el costo de prestar a una persona que
 no paga sus deudas es mayor que el costo de rechazar un préstamo a una
 persona que es pagadora.
 Los Verdaderos Positivos (True Positive - TP) y Verdaderos Negativos (True
 Negative - TN) son clasificaciones correctas.
 Un Falso Positivo (False Positive - FP) es cuando el resultado se predice
 incorrectamente como sí (o positivo) cuando es realmente no (o negativo).
 Un Falso Negativo (False Negative - FN) es cuando el resultado se predice
 incorrectamente como negativo cuando es realmente positivo.
 En la predicción multiclase, cada elemento de la matriz de confusión muestra
 el número de ejemplos de prueba para los que la clase real es la fila y
 la clase prevista es la columna.
 Son buenos resultados los grandes números en la diagonal principal e idealmente
 cero fuera de la diagonal principal.
 
\shape italic

\begin_inset Quotes eld
\end_inset

Kappa se utiliza para medir el acuerdo entre la predicción y la observación
 de las categorizaciones de un conjunto de datos, mientras que se corrige
 para un acuerdo que ocurre por casualidad
\begin_inset Quotes erd
\end_inset


\shape default
.
 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
 Si los evaluadores están totalmente de acuerdo, entonces Kappa alcanza
 su valor máximo y es igual a 1.
 Si no hay total acuerdo entre los evaluadores, entonces Kappa tiene un
 valor 
\begin_inset Formula $<1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\kappa=\frac{Pr\left(a\right)-Pr\left(e\right)}{1-Pr\left(e\right)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Donde: 
\begin_inset Formula $Pr\left(a\right)$
\end_inset

 es el acuerdo observado relativo entre los observadores y 
\begin_inset Formula $Pr\left(e\right)$
\end_inset

 es la probabilidad hipotética de acuerdo al azar utilizando los datos observado
s para calcular las probabilidades de que cada observador clasifique aleatoriame
nte cada categoría.
\end_layout

\begin_layout Subsubsection
Sensibilidad (Recall): Calcula la sensibilidad con respecto a una clase
 en particular, esto se define como: positivos correctamente clasificados
 / positivos totales
\begin_inset space ~
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Recall=\frac{TP}{TP+FN}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Precisión (Precision): Calcula la precisión con respecto a una clase en
 particular, esto se define como: positivos correctamente clasificados /
 total predicho como positivo 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Precision=\frac{TP}{TP+FP}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Puntuación-F (F-Measure): La Puntuación-F es una medida de la exactitud
 de una prueba.
 La Puntuación-F puede interpretarse como un promedio ponderado de la precisión
 y sensibilidad, donde alcanza su mejor valor en 1 y el peor en 0.
 Se define como: 2 * Recall * Precision / (Recall + Precision) 
\begin_inset CommandInset citation
LatexCommand cite
key "DM2011"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
F-Measure=\frac{2*Recall*Precision}{\left(Recall+Precision\right)}
\end{equation}

\end_inset


\end_layout

\end_body
\end_document
